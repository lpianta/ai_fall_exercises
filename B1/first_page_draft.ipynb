{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37964bitwebscrapingconda5dd7cefa095141818a3d3177a3640648",
   "display_name": "Python 3.7.9 64-bit ('web_scraping': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading libraries\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "94294', '993025', '440939', '2174123', '749353', '543817', '634352', '597999', '357987', '532897', '421345', '665780', '178609', '667489', '916185', '351277', '288639', '630119', '470894', '307212', '836250', '291354', '683082', '806220', '667769', '251017', '964559', '355301', '1475264', '370404', '112973', '360942', '333154', '225543', '234922', '549906', '603770', '160087', '300058', '252400', '206813', '259830', '612728', '271253', '267373', '159217', '349251', '490580', '308650', '164206', '152573', '259412', '527580', '82468', '2046639', '303497', '188017', '137062', '129755', '207947', '343510', '278419']\n",
      "['    92,942', '    72,334', '    115,308', '    68,950', '    57,960', '    49,521', '    29,782', '    41,241', '    49,354', '    58,682', '    22,562', '    17,595', '    31,434', '    31,464', '    20,079', '    35,159', '    57,135', '    65,994', '    38,474', '    27,541', '    25,282', '    19,948', '    72,315', '    11,365', '    23,521', '    5,394', '    30,447', '    24,100', '    54,413', '    18,500', '    10,525', '    34,272', '    25,967', '    43,661', '    18,177', '    10,515', '    23,863', '    11,158', '    21,046', '    29,682', '    14,015', '    82,716', '    23,902', '    17,019', '    9,573', '    18,076', '    17,585', '    15,838', '    20,867', '    23,483', '    3,738', '    18,596', '    19,426', '    15,880', '    13,969', '    21,419', '    25,501', '    9,169', '    12,025', '    4,184', '    12,295', '    25,712', '    32,063', '    12,024', '    33,929', '    15,217', '    30,971', '    13,095', '    6,916', '    10,703', '    13,105', '    10,020', '    15,259', '    12,079', '    9,419', '    7,203', '    12,284', '    6,650', '    5,568', '    4,513', '    14,138', '    14,012', '    9,852', '    6,108', '    11,281', '    19,085', '    8,723', '    5,754', '    7,796', '    14,628', '    19,402', '    2,584', '    54,959', '    6,585', '    6,776', '    7,724', '    5,419', '    16,841', '    11,104', '    4,957']\n"
     ]
    }
   ],
   "source": [
    "# getting page\n",
    "\n",
    "page = requests.get('https://www.goodreads.com/list/show/6.Best_Books_of_the_20th_Century')\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "# checking request result\n",
    "\n",
    "print(page)\n",
    "\n",
    "# trying scraping on one page\n",
    "\n",
    "# initializing empty lists\n",
    "num_rating_list = []\n",
    "avg_rating_list = []\n",
    "num_avg_list = []\n",
    "num_reviews_list = []\n",
    "\n",
    "# num of rating and average rating are in the same span, getting that span\n",
    "num_avg = soup.find_all('span', class_='minirating')\n",
    "\n",
    "# splitting the span to get number of ratings and average ratings\n",
    "for i in num_avg:\n",
    "    num_avg_list.append(i.get_text().strip().split(' â€” '))\n",
    "\n",
    "# assignin numbers and average to the corrisponding list\n",
    "for i in num_avg_list:\n",
    "    avg_rating_list.append(i[0])\n",
    "    num_rating_list.append(i[1])\n",
    "\n",
    "# using regex to get only the average rating without text (data cleaning)\n",
    "avg_rating_def = []\n",
    "for i in avg_rating_list:\n",
    "    i = re.sub('[^0-9.,]', '', i)\n",
    "    # updating list\n",
    "    avg_rating_def.append(i)\n",
    "\n",
    "print(avg_rating_def)\n",
    "\n",
    "# using regex to get only the number without text (data cleaning)\n",
    "num_rating_def = []\n",
    "for i in num_rating_list:\n",
    "    i = re.sub('[^0-9.]', '', i)\n",
    "    # updating list\n",
    "    num_rating_def.append(i)\n",
    "\n",
    "print(num_rating_def)\n",
    "\n",
    "# getting links to individual book pages to access number of reviews\n",
    "books_links = soup.find_all('a', class_='bookTitle', href=True)\n",
    "tags_list = []\n",
    "for i in books_links: \n",
    "    href = i['href']\n",
    "    tags_list.append(href)\n",
    "link_list = []\n",
    "for i in tags_list:\n",
    "    i = 'https://www.goodreads.com' + i\n",
    "    link_list.append(i)\n",
    "\n",
    "# looping through individual book pages to get number of reviews\n",
    "for link in link_list:\n",
    "    # getting new soup objects for every page\n",
    "    new_page = requests.get(link)\n",
    "    new_soup = BeautifulSoup(new_page.content, 'html.parser')\n",
    "    # getting element with number of reviews\n",
    "    num_reviews_soup = new_soup.find('div', class_='reviewControls--left greyText')\n",
    "    # cleaning data\n",
    "    num_reviews = num_reviews_soup.get_text().strip().split('\\n')[4]\n",
    "    num_reviews = re.sub('\\s+', '', num_reviews)\n",
    "    # updating list\n",
    "    num_reviews_list.append(num_reviews)\n",
    "print(num_reviews_list)\n"
   ]
  }
 ]
}