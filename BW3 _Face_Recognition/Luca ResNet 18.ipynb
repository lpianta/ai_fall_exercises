{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "processed-origin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "operating-seller",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading trainiter and testier\n",
    "\n",
    "trainloader = torch.load('../../1_Data_Loader/Data_Loader_files/trainloader_V1_resnet18.pt')\n",
    "testloader = torch.load('../../1_Data_Loader/Data_Loader_files/testloader_V1_resnet18.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "united-wonder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 224, 224]) 16\n"
     ]
    }
   ],
   "source": [
    "# testing the trainloader\n",
    "train_examples = iter(trainloader)\n",
    "train_samples, train_labels = train_examples.next()\n",
    "print(train_samples.shape, len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "single-klein",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 224, 224]) tensor([1, 2, 0, 1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 2, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "# testing the testloader\n",
    "test_examples = iter(testloader)\n",
    "test_samples, test_labels = test_examples.next()\n",
    "print(test_samples.shape, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "greater-profession",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting GPU if it's available\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "pressed-israeli",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing resnet18\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "handmade-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.fc = nn.Sequential(nn.Linear(512, 10),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.2),\n",
    "                                 nn.Linear(10, 3),\n",
    "                                 nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dominican-sunglasses",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "graduate-joshua",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5.. Train loss: 0.567.. Test loss: 1.210.. Test accuracy: 0.547\n",
      "Epoch 1/5.. Train loss: 0.566.. Test loss: 1.135.. Test accuracy: 0.552\n",
      "Epoch 1/5.. Train loss: 0.514.. Test loss: 0.877.. Test accuracy: 0.581\n",
      "Epoch 1/5.. Train loss: 0.413.. Test loss: 1.090.. Test accuracy: 0.555\n",
      "Epoch 1/5.. Train loss: 0.457.. Test loss: 1.332.. Test accuracy: 0.574\n",
      "Epoch 1/5.. Train loss: 0.480.. Test loss: 1.306.. Test accuracy: 0.571\n",
      "Epoch 1/5.. Train loss: 0.459.. Test loss: 0.894.. Test accuracy: 0.585\n",
      "Epoch 1/5.. Train loss: 0.445.. Test loss: 0.895.. Test accuracy: 0.572\n",
      "Epoch 1/5.. Train loss: 0.460.. Test loss: 1.295.. Test accuracy: 0.536\n",
      "Epoch 1/5.. Train loss: 0.631.. Test loss: 1.224.. Test accuracy: 0.592\n",
      "Epoch 1/5.. Train loss: 0.462.. Test loss: 1.237.. Test accuracy: 0.567\n",
      "Epoch 1/5.. Train loss: 0.667.. Test loss: 0.992.. Test accuracy: 0.535\n",
      "Epoch 1/5.. Train loss: 0.506.. Test loss: 0.887.. Test accuracy: 0.541\n",
      "Epoch 1/5.. Train loss: 0.396.. Test loss: 1.029.. Test accuracy: 0.594\n",
      "Epoch 1/5.. Train loss: 0.445.. Test loss: 1.387.. Test accuracy: 0.592\n",
      "Epoch 1/5.. Train loss: 0.472.. Test loss: 1.301.. Test accuracy: 0.545\n",
      "Epoch 1/5.. Train loss: 0.497.. Test loss: 0.782.. Test accuracy: 0.592\n",
      "Epoch 1/5.. Train loss: 0.525.. Test loss: 0.714.. Test accuracy: 0.597\n",
      "Epoch 1/5.. Train loss: 0.411.. Test loss: 0.919.. Test accuracy: 0.538\n",
      "Epoch 1/5.. Train loss: 0.555.. Test loss: 1.012.. Test accuracy: 0.586\n",
      "Epoch 1/5.. Train loss: 0.496.. Test loss: 1.390.. Test accuracy: 0.583\n",
      "Epoch 1/5.. Train loss: 0.461.. Test loss: 1.317.. Test accuracy: 0.570\n",
      "Epoch 1/5.. Train loss: 0.483.. Test loss: 1.075.. Test accuracy: 0.577\n",
      "Epoch 1/5.. Train loss: 0.325.. Test loss: 0.961.. Test accuracy: 0.584\n",
      "Epoch 1/5.. Train loss: 0.387.. Test loss: 1.091.. Test accuracy: 0.588\n",
      "Epoch 1/5.. Train loss: 0.520.. Test loss: 0.954.. Test accuracy: 0.602\n",
      "Epoch 1/5.. Train loss: 0.383.. Test loss: 0.882.. Test accuracy: 0.644\n",
      "Epoch 1/5.. Train loss: 0.374.. Test loss: 0.927.. Test accuracy: 0.643\n",
      "Epoch 1/5.. Train loss: 0.450.. Test loss: 1.168.. Test accuracy: 0.616\n",
      "Epoch 1/5.. Train loss: 0.449.. Test loss: 1.367.. Test accuracy: 0.631\n",
      "Epoch 1/5.. Train loss: 0.328.. Test loss: 1.194.. Test accuracy: 0.639\n",
      "Epoch 1/5.. Train loss: 0.328.. Test loss: 1.124.. Test accuracy: 0.654\n",
      "Epoch 1/5.. Train loss: 0.328.. Test loss: 1.113.. Test accuracy: 0.650\n",
      "Epoch 1/5.. Train loss: 0.380.. Test loss: 1.244.. Test accuracy: 0.633\n",
      "Epoch 1/5.. Train loss: 0.244.. Test loss: 1.274.. Test accuracy: 0.599\n",
      "Epoch 2/5.. Train loss: 0.216.. Test loss: 1.711.. Test accuracy: 0.541\n",
      "Epoch 2/5.. Train loss: 0.583.. Test loss: 1.608.. Test accuracy: 0.554\n",
      "Epoch 2/5.. Train loss: 0.900.. Test loss: 1.028.. Test accuracy: 0.635\n",
      "Epoch 2/5.. Train loss: 0.363.. Test loss: 0.915.. Test accuracy: 0.621\n",
      "Epoch 2/5.. Train loss: 0.380.. Test loss: 0.912.. Test accuracy: 0.627\n",
      "Epoch 2/5.. Train loss: 0.323.. Test loss: 1.090.. Test accuracy: 0.612\n",
      "Epoch 2/5.. Train loss: 0.473.. Test loss: 1.292.. Test accuracy: 0.617\n",
      "Epoch 2/5.. Train loss: 0.323.. Test loss: 1.182.. Test accuracy: 0.652\n",
      "Epoch 2/5.. Train loss: 0.260.. Test loss: 1.202.. Test accuracy: 0.640\n",
      "Epoch 2/5.. Train loss: 0.503.. Test loss: 0.859.. Test accuracy: 0.697\n",
      "Epoch 2/5.. Train loss: 0.360.. Test loss: 0.756.. Test accuracy: 0.683\n",
      "Epoch 2/5.. Train loss: 0.354.. Test loss: 0.850.. Test accuracy: 0.657\n",
      "Epoch 2/5.. Train loss: 0.319.. Test loss: 1.069.. Test accuracy: 0.587\n",
      "Epoch 2/5.. Train loss: 0.382.. Test loss: 1.129.. Test accuracy: 0.618\n",
      "Epoch 2/5.. Train loss: 0.278.. Test loss: 0.946.. Test accuracy: 0.692\n",
      "Epoch 2/5.. Train loss: 0.414.. Test loss: 1.172.. Test accuracy: 0.666\n",
      "Epoch 2/5.. Train loss: 0.259.. Test loss: 1.048.. Test accuracy: 0.689\n",
      "Epoch 2/5.. Train loss: 0.207.. Test loss: 1.093.. Test accuracy: 0.677\n",
      "Epoch 2/5.. Train loss: 0.295.. Test loss: 1.093.. Test accuracy: 0.690\n",
      "Epoch 2/5.. Train loss: 0.272.. Test loss: 1.200.. Test accuracy: 0.669\n",
      "Epoch 2/5.. Train loss: 0.384.. Test loss: 1.268.. Test accuracy: 0.675\n",
      "Epoch 2/5.. Train loss: 0.296.. Test loss: 1.021.. Test accuracy: 0.701\n",
      "Epoch 2/5.. Train loss: 0.244.. Test loss: 0.796.. Test accuracy: 0.714\n",
      "Epoch 2/5.. Train loss: 0.327.. Test loss: 0.859.. Test accuracy: 0.713\n",
      "Epoch 2/5.. Train loss: 0.252.. Test loss: 1.078.. Test accuracy: 0.676\n",
      "Epoch 2/5.. Train loss: 0.246.. Test loss: 1.090.. Test accuracy: 0.692\n",
      "Epoch 2/5.. Train loss: 0.261.. Test loss: 1.001.. Test accuracy: 0.706\n",
      "Epoch 2/5.. Train loss: 0.288.. Test loss: 1.280.. Test accuracy: 0.661\n",
      "Epoch 2/5.. Train loss: 0.432.. Test loss: 1.105.. Test accuracy: 0.682\n",
      "Epoch 2/5.. Train loss: 0.370.. Test loss: 1.179.. Test accuracy: 0.678\n",
      "Epoch 2/5.. Train loss: 0.332.. Test loss: 1.136.. Test accuracy: 0.681\n",
      "Epoch 2/5.. Train loss: 0.391.. Test loss: 0.936.. Test accuracy: 0.705\n",
      "Epoch 2/5.. Train loss: 0.326.. Test loss: 1.098.. Test accuracy: 0.671\n",
      "Epoch 2/5.. Train loss: 0.319.. Test loss: 1.448.. Test accuracy: 0.664\n",
      "Epoch 2/5.. Train loss: 0.338.. Test loss: 1.069.. Test accuracy: 0.694\n",
      "Epoch 3/5.. Train loss: 0.285.. Test loss: 0.911.. Test accuracy: 0.715\n",
      "Epoch 3/5.. Train loss: 0.355.. Test loss: 0.881.. Test accuracy: 0.707\n",
      "Epoch 3/5.. Train loss: 0.185.. Test loss: 1.007.. Test accuracy: 0.717\n",
      "Epoch 3/5.. Train loss: 0.281.. Test loss: 1.350.. Test accuracy: 0.655\n",
      "Epoch 3/5.. Train loss: 0.360.. Test loss: 0.964.. Test accuracy: 0.685\n",
      "Epoch 3/5.. Train loss: 0.286.. Test loss: 1.041.. Test accuracy: 0.683\n",
      "Epoch 3/5.. Train loss: 0.395.. Test loss: 1.284.. Test accuracy: 0.667\n",
      "Epoch 3/5.. Train loss: 0.303.. Test loss: 1.909.. Test accuracy: 0.648\n",
      "Epoch 3/5.. Train loss: 0.385.. Test loss: 1.783.. Test accuracy: 0.665\n",
      "Epoch 3/5.. Train loss: 0.267.. Test loss: 1.125.. Test accuracy: 0.702\n",
      "Epoch 3/5.. Train loss: 0.278.. Test loss: 1.064.. Test accuracy: 0.691\n",
      "Epoch 3/5.. Train loss: 0.348.. Test loss: 1.171.. Test accuracy: 0.688\n",
      "Epoch 3/5.. Train loss: 0.324.. Test loss: 1.026.. Test accuracy: 0.700\n",
      "Epoch 3/5.. Train loss: 0.342.. Test loss: 0.951.. Test accuracy: 0.711\n",
      "Epoch 3/5.. Train loss: 0.221.. Test loss: 1.107.. Test accuracy: 0.697\n",
      "Epoch 3/5.. Train loss: 0.210.. Test loss: 1.549.. Test accuracy: 0.654\n",
      "Epoch 3/5.. Train loss: 0.313.. Test loss: 1.520.. Test accuracy: 0.671\n",
      "Epoch 3/5.. Train loss: 0.239.. Test loss: 1.054.. Test accuracy: 0.712\n",
      "Epoch 3/5.. Train loss: 0.310.. Test loss: 0.961.. Test accuracy: 0.710\n",
      "Epoch 3/5.. Train loss: 0.186.. Test loss: 1.126.. Test accuracy: 0.667\n",
      "Epoch 3/5.. Train loss: 0.279.. Test loss: 1.137.. Test accuracy: 0.672\n",
      "Epoch 3/5.. Train loss: 0.278.. Test loss: 1.013.. Test accuracy: 0.714\n",
      "Epoch 3/5.. Train loss: 0.196.. Test loss: 1.141.. Test accuracy: 0.703\n",
      "Epoch 3/5.. Train loss: 0.326.. Test loss: 1.419.. Test accuracy: 0.670\n",
      "Epoch 3/5.. Train loss: 0.476.. Test loss: 1.088.. Test accuracy: 0.694\n",
      "Epoch 3/5.. Train loss: 0.288.. Test loss: 1.032.. Test accuracy: 0.687\n",
      "Epoch 3/5.. Train loss: 0.249.. Test loss: 1.028.. Test accuracy: 0.705\n",
      "Epoch 3/5.. Train loss: 0.417.. Test loss: 1.071.. Test accuracy: 0.704\n",
      "Epoch 3/5.. Train loss: 0.409.. Test loss: 1.084.. Test accuracy: 0.725\n",
      "Epoch 3/5.. Train loss: 0.256.. Test loss: 1.207.. Test accuracy: 0.704\n",
      "Epoch 3/5.. Train loss: 0.408.. Test loss: 1.492.. Test accuracy: 0.675\n",
      "Epoch 3/5.. Train loss: 0.297.. Test loss: 1.571.. Test accuracy: 0.662\n",
      "Epoch 3/5.. Train loss: 0.372.. Test loss: 1.307.. Test accuracy: 0.683\n",
      "Epoch 4/5.. Train loss: 0.336.. Test loss: 1.373.. Test accuracy: 0.664\n",
      "Epoch 4/5.. Train loss: 0.316.. Test loss: 1.123.. Test accuracy: 0.691\n",
      "Epoch 4/5.. Train loss: 0.263.. Test loss: 1.141.. Test accuracy: 0.710\n",
      "Epoch 4/5.. Train loss: 0.304.. Test loss: 1.301.. Test accuracy: 0.676\n",
      "Epoch 4/5.. Train loss: 0.194.. Test loss: 1.740.. Test accuracy: 0.671\n",
      "Epoch 4/5.. Train loss: 0.211.. Test loss: 1.822.. Test accuracy: 0.669\n",
      "Epoch 4/5.. Train loss: 0.260.. Test loss: 1.536.. Test accuracy: 0.697\n",
      "Epoch 4/5.. Train loss: 0.371.. Test loss: 1.335.. Test accuracy: 0.712\n",
      "Epoch 4/5.. Train loss: 0.345.. Test loss: 1.486.. Test accuracy: 0.688\n",
      "Epoch 4/5.. Train loss: 0.154.. Test loss: 1.668.. Test accuracy: 0.685\n",
      "Epoch 4/5.. Train loss: 0.265.. Test loss: 1.747.. Test accuracy: 0.675\n",
      "Epoch 4/5.. Train loss: 0.142.. Test loss: 1.570.. Test accuracy: 0.680\n",
      "Epoch 4/5.. Train loss: 0.373.. Test loss: 1.608.. Test accuracy: 0.698\n",
      "Epoch 4/5.. Train loss: 0.385.. Test loss: 1.384.. Test accuracy: 0.706\n",
      "Epoch 4/5.. Train loss: 0.314.. Test loss: 1.100.. Test accuracy: 0.711\n",
      "Epoch 4/5.. Train loss: 0.247.. Test loss: 0.900.. Test accuracy: 0.733\n",
      "Epoch 4/5.. Train loss: 0.248.. Test loss: 1.204.. Test accuracy: 0.704\n",
      "Epoch 4/5.. Train loss: 0.174.. Test loss: 1.505.. Test accuracy: 0.689\n",
      "Epoch 4/5.. Train loss: 0.360.. Test loss: 1.540.. Test accuracy: 0.684\n",
      "Epoch 4/5.. Train loss: 0.265.. Test loss: 1.489.. Test accuracy: 0.701\n",
      "Epoch 4/5.. Train loss: 0.259.. Test loss: 1.539.. Test accuracy: 0.703\n",
      "Epoch 4/5.. Train loss: 0.257.. Test loss: 1.246.. Test accuracy: 0.709\n",
      "Epoch 4/5.. Train loss: 0.441.. Test loss: 1.341.. Test accuracy: 0.684\n",
      "Epoch 4/5.. Train loss: 0.331.. Test loss: 1.582.. Test accuracy: 0.681\n",
      "Epoch 4/5.. Train loss: 0.317.. Test loss: 1.383.. Test accuracy: 0.696\n",
      "Epoch 4/5.. Train loss: 0.232.. Test loss: 1.371.. Test accuracy: 0.695\n",
      "Epoch 4/5.. Train loss: 0.215.. Test loss: 1.406.. Test accuracy: 0.698\n",
      "Epoch 4/5.. Train loss: 0.234.. Test loss: 1.531.. Test accuracy: 0.692\n",
      "Epoch 4/5.. Train loss: 0.228.. Test loss: 1.297.. Test accuracy: 0.711\n",
      "Epoch 4/5.. Train loss: 0.418.. Test loss: 1.284.. Test accuracy: 0.708\n",
      "Epoch 4/5.. Train loss: 0.142.. Test loss: 1.545.. Test accuracy: 0.665\n",
      "Epoch 4/5.. Train loss: 0.340.. Test loss: 1.507.. Test accuracy: 0.679\n",
      "Epoch 4/5.. Train loss: 0.227.. Test loss: 1.170.. Test accuracy: 0.692\n",
      "Epoch 4/5.. Train loss: 0.297.. Test loss: 1.246.. Test accuracy: 0.677\n",
      "Epoch 4/5.. Train loss: 0.210.. Test loss: 1.124.. Test accuracy: 0.698\n",
      "Epoch 5/5.. Train loss: 0.234.. Test loss: 1.285.. Test accuracy: 0.696\n",
      "Epoch 5/5.. Train loss: 0.333.. Test loss: 1.329.. Test accuracy: 0.697\n",
      "Epoch 5/5.. Train loss: 0.223.. Test loss: 1.277.. Test accuracy: 0.707\n",
      "Epoch 5/5.. Train loss: 0.324.. Test loss: 1.236.. Test accuracy: 0.712\n",
      "Epoch 5/5.. Train loss: 0.239.. Test loss: 1.361.. Test accuracy: 0.708\n",
      "Epoch 5/5.. Train loss: 0.318.. Test loss: 1.473.. Test accuracy: 0.702\n",
      "Epoch 5/5.. Train loss: 0.310.. Test loss: 1.748.. Test accuracy: 0.694\n",
      "Epoch 5/5.. Train loss: 0.214.. Test loss: 1.452.. Test accuracy: 0.700\n",
      "Epoch 5/5.. Train loss: 0.382.. Test loss: 1.264.. Test accuracy: 0.716\n",
      "Epoch 5/5.. Train loss: 0.331.. Test loss: 1.347.. Test accuracy: 0.674\n",
      "Epoch 5/5.. Train loss: 0.211.. Test loss: 1.591.. Test accuracy: 0.641\n",
      "Epoch 5/5.. Train loss: 0.224.. Test loss: 1.267.. Test accuracy: 0.682\n",
      "Epoch 5/5.. Train loss: 0.229.. Test loss: 1.253.. Test accuracy: 0.702\n",
      "Epoch 5/5.. Train loss: 0.316.. Test loss: 1.316.. Test accuracy: 0.703\n",
      "Epoch 5/5.. Train loss: 0.226.. Test loss: 1.447.. Test accuracy: 0.706\n",
      "Epoch 5/5.. Train loss: 0.310.. Test loss: 1.762.. Test accuracy: 0.669\n",
      "Epoch 5/5.. Train loss: 0.397.. Test loss: 1.371.. Test accuracy: 0.710\n",
      "Epoch 5/5.. Train loss: 0.331.. Test loss: 1.010.. Test accuracy: 0.699\n",
      "Epoch 5/5.. Train loss: 0.271.. Test loss: 1.062.. Test accuracy: 0.710\n",
      "Epoch 5/5.. Train loss: 0.245.. Test loss: 1.317.. Test accuracy: 0.699\n",
      "Epoch 5/5.. Train loss: 0.229.. Test loss: 1.770.. Test accuracy: 0.640\n",
      "Epoch 5/5.. Train loss: 0.214.. Test loss: 1.858.. Test accuracy: 0.662\n",
      "Epoch 5/5.. Train loss: 0.203.. Test loss: 1.729.. Test accuracy: 0.692\n",
      "Epoch 5/5.. Train loss: 0.223.. Test loss: 1.334.. Test accuracy: 0.707\n",
      "Epoch 5/5.. Train loss: 0.289.. Test loss: 1.206.. Test accuracy: 0.731\n",
      "Epoch 5/5.. Train loss: 0.259.. Test loss: 1.291.. Test accuracy: 0.728\n",
      "Epoch 5/5.. Train loss: 0.261.. Test loss: 1.457.. Test accuracy: 0.698\n",
      "Epoch 5/5.. Train loss: 0.344.. Test loss: 1.236.. Test accuracy: 0.712\n",
      "Epoch 5/5.. Train loss: 0.306.. Test loss: 1.291.. Test accuracy: 0.711\n",
      "Epoch 5/5.. Train loss: 0.242.. Test loss: 1.194.. Test accuracy: 0.732\n",
      "Epoch 5/5.. Train loss: 0.273.. Test loss: 1.396.. Test accuracy: 0.691\n",
      "Epoch 5/5.. Train loss: 0.175.. Test loss: 1.642.. Test accuracy: 0.685\n",
      "Epoch 5/5.. Train loss: 0.297.. Test loss: 1.571.. Test accuracy: 0.697\n",
      "Epoch 5/5.. Train loss: 0.311.. Test loss: 0.843.. Test accuracy: 0.747\n",
      "Epoch 5/5.. Train loss: 0.318.. Test loss: 0.838.. Test accuracy: 0.737\n",
      "Epoch 5/5.. Train loss: 0.162.. Test loss: 1.277.. Test accuracy: 0.649\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 5\n",
    "max_accuracy = 0\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in trainloader:\n",
    "        \n",
    "        steps += 1\n",
    "        # Move input and label tensors to the default device\n",
    "        # inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logps = model.forward(inputs)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in testloader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    logps = model.forward(inputs)\n",
    "                    batch_loss = criterion(logps, labels)\n",
    "                    \n",
    "                    test_loss += batch_loss.item()\n",
    "                    \n",
    "                    # Calculate accuracy\n",
    "                    ps = torch.exp(logps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "                    if accuracy >= max_accuracy:\n",
    "                        max_accuracy = accuracy\n",
    "                        torch.save(model.state_dict(), 'checkpoint.pth')\n",
    "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                  f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
    "                  f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
    "            running_loss = 0\n",
    "            model.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "american-revelation",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../Model_files/resnet18luca.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "failing-bikini",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx\n",
    "from torch.autograd import Variable\n",
    "\n",
    "dummy_input = Variable(torch.randn(1, 3, 224, 224)) \n",
    "\n",
    "torch.onnx.export(model,\n",
    "                  dummy_input,\n",
    "                  \"../Model_files/resnet18_luca.onnx\",\n",
    "                  export_params=True,\n",
    "                  opset_version=10)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
