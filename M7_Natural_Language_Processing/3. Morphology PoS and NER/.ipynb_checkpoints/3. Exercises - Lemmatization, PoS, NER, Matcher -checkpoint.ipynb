{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "valid-consultation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T19:32:23.755820Z",
     "start_time": "2021-03-30T19:32:22.644310Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-mortgage",
   "metadata": {},
   "source": [
    "## Lemmatization\n",
    "\n",
    "**Exercise 1.1**\n",
    "\n",
    "You are given the words \"playing\", \"played\", \"play\". Find the lemma using spaCy for all of them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "english-plate",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T19:34:20.464484Z",
     "start_time": "2021-03-30T19:34:20.425793Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lemma of the word \"playing\" is play\n",
      "The lemma of the word \"played\" is play\n",
      "The lemma of the word \"playing\" is play\n"
     ]
    }
   ],
   "source": [
    "words = [\"playing\", \"played\", \"playing\"]\n",
    "\n",
    "for word in words:\n",
    "    nlp_word = nlp(word)\n",
    "    for i in nlp_word:\n",
    "        print(f'The lemma of the word \"{nlp_word.text}\" is {i.lemma_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-commonwealth",
   "metadata": {},
   "source": [
    "**Exercise 1.2**\n",
    "\n",
    "Assign the spaCy lemmatizer to a variable instead of using the whole `nlp` pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-damage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "clinical-champion",
   "metadata": {},
   "source": [
    "**Exercise 1.3**\n",
    "\n",
    "Find the verb, the noun and the adjective forms of the words: \"playing\", \"played\", \"surfing\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-blood",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T19:41:42.605031Z",
     "start_time": "2021-03-30T19:41:42.595092Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "documentary-heart",
   "metadata": {},
   "source": [
    "## Spell Checker\n",
    "\n",
    "**Exercise 1.4**\n",
    "\n",
    "In the following sentences there are some mispelling errors. Can you preprocess them to get rid of them? \n",
    "\n",
    "*N.B. there's no perfect spell-checker. Don't waste time on this. But be aware that it can be useful sometimes.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "caroline-agency",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T20:10:59.239954Z",
     "start_time": "2021-03-30T20:10:59.087475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i really like this exercise\n",
      "tis sentences are surely writer by an italian\n",
      "lets fix thissssss\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"i realy like this exerxise\", \n",
    "             \"tis sentences are surely writen by an italian\",\n",
    "             \"lets fix thissssss\"\n",
    "            ]\n",
    "\n",
    "from autocorrect import Speller\n",
    "\n",
    "spell = Speller()\n",
    "\n",
    "for i in sentences:\n",
    "    print(spell(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-imperial",
   "metadata": {},
   "source": [
    "## POS Tagging\n",
    "\n",
    "**Exercise 1.5 (★☆☆)**\n",
    "\n",
    "The training of TAs to survive the first two weeks at Strive School consists of the following sets:\n",
    "\n",
    "- 1000 reps of \"Did you google it?\"\n",
    "- 1000 reps of \"Did you search it on Google already?\"\n",
    "\n",
    "Use spaCy to explain the difference of the word \"google\" in the two sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "dried-tulsa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "respiratory-priest",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T04:57:52.063503Z",
     "start_time": "2021-03-31T04:57:51.819028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google -- VERB -- VB -- verb, base form\n",
      "Google -- PROPN -- NNP -- noun, proper singular\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"Did you google it?\",\n",
    "             \"Did you search it on Google already?\"]\n",
    "\n",
    "for sent in sentences:\n",
    "    nlp_sent = nlp(sent)\n",
    "    for word in nlp_sent:\n",
    "        if word.text.lower() == 'google':\n",
    "            print(f'{word} -- {word.pos_} -- {word.tag_} -- {spacy.explain(word.tag_)}')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-iceland",
   "metadata": {},
   "source": [
    "**Exercise 1.5 (★★☆)**\n",
    "\n",
    "Get the frequencies of the POS tags in the example sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "rational-xerox",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T05:17:13.245020Z",
     "start_time": "2021-03-31T05:17:13.220428Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'DET': 3,\n",
       "         'AUX': 1,\n",
       "         'NOUN': 3,\n",
       "         'PUNCT': 2,\n",
       "         'SPACE': 1,\n",
       "         'PROPN': 2,\n",
       "         'ADP': 1,\n",
       "         'PRON': 1})"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "sentence = \"\"\"This is an example sentence.\n",
    "            Count the POS tags in it.\"\"\"\n",
    "\n",
    "doc = nlp(sentence)\n",
    "\n",
    "token_list = []\n",
    "\n",
    "for token in doc:\n",
    "    token_list.append(token.pos_)\n",
    "    \n",
    "pos_count = Counter(token_list)\n",
    "pos_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-label",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T05:09:39.399233Z",
     "start_time": "2021-03-31T05:09:39.364673Z"
    }
   },
   "source": [
    "**Exercise 1.7 (★★★)**\n",
    "\n",
    "(This exercises requires many steps in Pandas, no unique solution. You can hard code the name of the columns for this example if you get stuck.)\n",
    "\n",
    "Loading 10 tweets from the twitter datasets, create a dataframe containing the frequencies of each POS per tweet (see example).\n",
    "\n",
    "N.B. The column names must be the tags not the indices of the tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "fifth-dispute",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T06:16:19.616337Z",
     "start_time": "2021-03-31T06:16:19.498649Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/stock_data.csv\")\n",
    "\n",
    "df = df.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "outstanding-commonwealth",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T06:16:19.660774Z",
     "start_time": "2021-03-31T06:16:19.656353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNTA Over 12.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OI  Over 21.37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PGNX  Over 3.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAP - user if so then the current downtrend wi...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Monday's relative weakness. NYX WIN TIE TAP IC...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GOOG - ower trend line channel test &amp; volume s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AAP will watch tomorrow for ONG entry.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment\n",
       "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1\n",
       "1  user: AAP MOVIE. 55% return for the FEA/GEED i...          1\n",
       "2  user I'd be afraid to short AMZN - they are lo...          1\n",
       "3                                  MNTA Over 12.00            1\n",
       "4                                   OI  Over 21.37            1\n",
       "5                                  PGNX  Over 3.04            1\n",
       "6  AAP - user if so then the current downtrend wi...         -1\n",
       "7  Monday's relative weakness. NYX WIN TIE TAP IC...         -1\n",
       "8  GOOG - ower trend line channel test & volume s...          1\n",
       "9             AAP will watch tomorrow for ONG entry.          1"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "median-discrimination",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T05:26:12.875138Z",
     "start_time": "2021-03-31T05:26:12.865565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NOUN': 7, 'ADP': 1, 'PRON': 1, 'PROPN': 7, 'SPACE': 1, 'NUM': 2, 'CCONJ': 1, 'PUNCT': 1, 'VERB': 1}\n"
     ]
    }
   ],
   "source": [
    "sent1 = df['Text'].values[0]\n",
    "doc1 = nlp(sent1)\n",
    "token_list = []\n",
    "\n",
    "for token in doc1:\n",
    "    token_list.append(token.pos_)\n",
    "    \n",
    "pos_count = Counter(token_list)\n",
    "dict_count = dict(pos_count)\n",
    "dict_count.values()\n",
    "print(dict_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "coordinated-olympus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>ADP</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>SPACE</th>\n",
       "      <th>VERB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNTA Over 12.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OI  Over 21.37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PGNX  Over 3.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAP - user if so then the current downtrend wi...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Monday's relative weakness. NYX WIN TIE TAP IC...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GOOG - ower trend line channel test &amp; volume s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AAP will watch tomorrow for ONG entry.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text  Sentiment  ADP  CCONJ  \\\n",
       "0   Kickers on my watchlist XIDE TIT SOQ PNK CPW B...        1.0  NaN    NaN   \n",
       "1   user: AAP MOVIE. 55% return for the FEA/GEED i...        1.0  NaN    NaN   \n",
       "2   user I'd be afraid to short AMZN - they are lo...        1.0  NaN    NaN   \n",
       "3                                   MNTA Over 12.00          1.0  NaN    NaN   \n",
       "4                                    OI  Over 21.37          1.0  NaN    NaN   \n",
       "5                                   PGNX  Over 3.04          1.0  NaN    NaN   \n",
       "6   AAP - user if so then the current downtrend wi...       -1.0  NaN    NaN   \n",
       "7   Monday's relative weakness. NYX WIN TIE TAP IC...       -1.0  NaN    NaN   \n",
       "8   GOOG - ower trend line channel test & volume s...        1.0  NaN    NaN   \n",
       "9              AAP will watch tomorrow for ONG entry.        1.0  NaN    NaN   \n",
       "10                                                NaN        NaN  1.0    1.0   \n",
       "\n",
       "    NOUN  NUM  PRON  PROPN  PUNCT  SPACE  VERB  \n",
       "0    NaN  NaN   NaN    NaN    NaN    NaN   NaN  \n",
       "1    NaN  NaN   NaN    NaN    NaN    NaN   NaN  \n",
       "2    NaN  NaN   NaN    NaN    NaN    NaN   NaN  \n",
       "3    NaN  NaN   NaN    NaN    NaN    NaN   NaN  \n",
       "4    NaN  NaN   NaN    NaN    NaN    NaN   NaN  \n",
       "5    NaN  NaN   NaN    NaN    NaN    NaN   NaN  \n",
       "6    NaN  NaN   NaN    NaN    NaN    NaN   NaN  \n",
       "7    NaN  NaN   NaN    NaN    NaN    NaN   NaN  \n",
       "8    NaN  NaN   NaN    NaN    NaN    NaN   NaN  \n",
       "9    NaN  NaN   NaN    NaN    NaN    NaN   NaN  \n",
       "10   7.0  2.0   1.0    7.0    1.0    1.0   1.0  "
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.append(dict_count, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "tropical-detective",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T05:34:45.822225Z",
     "start_time": "2021-03-31T05:34:45.814005Z"
    }
   },
   "outputs": [],
   "source": [
    "columns = ['NOUN',\n",
    " 'ADP',\n",
    " 'DET',\n",
    " 'PROPN',\n",
    " 'SPACE',\n",
    " 'NUM',\n",
    " 'CCONJ',\n",
    " 'PUNCT',\n",
    " 'VERB',\n",
    " 'SYM',\n",
    " 'ADV',\n",
    " 'PRON',\n",
    " 'AUX',\n",
    " 'ADJ',\n",
    " 'PART',\n",
    " 'SCONJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "collective-missouri",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T05:50:57.001480Z",
     "start_time": "2021-03-31T05:50:56.992453Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>ADP</th>\n",
       "      <th>DET</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>SPACE</th>\n",
       "      <th>NUM</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>VERB</th>\n",
       "      <th>SYM</th>\n",
       "      <th>ADV</th>\n",
       "      <th>PRON</th>\n",
       "      <th>AUX</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>PART</th>\n",
       "      <th>SCONJ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Text  NOUN  ADP  DET  PROPN  SPACE  NUM  CCONJ  PUNCT  VERB  SYM  ADV  \\\n",
       "0   0.0   0.0  0.0  0.0    0.0    0.0  0.0    0.0    0.0   0.0  0.0  0.0   \n",
       "1   0.0   0.0  0.0  0.0    0.0    0.0  0.0    0.0    0.0   0.0  0.0  0.0   \n",
       "2   0.0   0.0  0.0  0.0    0.0    0.0  0.0    0.0    0.0   0.0  0.0  0.0   \n",
       "3   0.0   0.0  0.0  0.0    0.0    0.0  0.0    0.0    0.0   0.0  0.0  0.0   \n",
       "4   0.0   0.0  0.0  0.0    0.0    0.0  0.0    0.0    0.0   0.0  0.0  0.0   \n",
       "5   0.0   0.0  0.0  0.0    0.0    0.0  0.0    0.0    0.0   0.0  0.0  0.0   \n",
       "6   0.0   0.0  0.0  0.0    0.0    0.0  0.0    0.0    0.0   0.0  0.0  0.0   \n",
       "7   0.0   0.0  0.0  0.0    0.0    0.0  0.0    0.0    0.0   0.0  0.0  0.0   \n",
       "8   0.0   0.0  0.0  0.0    0.0    0.0  0.0    0.0    0.0   0.0  0.0  0.0   \n",
       "9   0.0   0.0  0.0  0.0    0.0    0.0  0.0    0.0    0.0   0.0  0.0  0.0   \n",
       "\n",
       "   PRON  AUX  ADJ  PART  SCONJ  \n",
       "0   0.0  0.0  0.0   0.0    0.0  \n",
       "1   0.0  0.0  0.0   0.0    0.0  \n",
       "2   0.0  0.0  0.0   0.0    0.0  \n",
       "3   0.0  0.0  0.0   0.0    0.0  \n",
       "4   0.0  0.0  0.0   0.0    0.0  \n",
       "5   0.0  0.0  0.0   0.0    0.0  \n",
       "6   0.0  0.0  0.0   0.0    0.0  \n",
       "7   0.0  0.0  0.0   0.0    0.0  \n",
       "8   0.0  0.0  0.0   0.0    0.0  \n",
       "9   0.0  0.0  0.0   0.0    0.0  "
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "array = np.zeros((10,len(columns)+1))\n",
    "data = pd.DataFrame(array, columns=[\"Text\", *columns])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "designed-mobile",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T05:50:57.313768Z",
     "start_time": "2021-03-31T05:50:57.211856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NOUN</th>\n",
       "      <th>ADP</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>SPACE</th>\n",
       "      <th>NUM</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>VERB</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0 NOUN ADP PRON PROPN SPACE NUM CCONJ PUNCT VERB  \\\n",
       "1    7   1    1     7     1   2     1     1    1   \n",
       "\n",
       "0                                               Text  \n",
       "1  user: AAP MOVIE. 55% return for the FEA/GEED i...  "
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0 = pd.DataFrame(list(dict_count.items()), index=range(0,9))\n",
    "df_t = df0.T\n",
    "df_t.columns = df_t.iloc[0]\n",
    "df_t = df_t.drop(0)\n",
    "df_t['Text'] = df['Text']\n",
    "df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "rural-ceremony",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T05:50:57.385440Z",
     "start_time": "2021-03-31T05:50:57.369822Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NOUN': 7, 'ADP': 1, 'PRON': 1, 'PROPN': 7, 'SPACE': 1, 'NUM': 2, 'CCONJ': 1, 'PUNCT': 1, 'VERB': 1}\n",
      "{'NOUN': 6, 'PUNCT': 4, 'PROPN': 5, 'NUM': 2, 'ADP': 2, 'DET': 2, 'SYM': 1, 'ADV': 1, 'SPACE': 2}\n",
      "{'NOUN': 4, 'PRON': 2, 'AUX': 3, 'VERB': 2, 'ADJ': 3, 'PROPN': 2, 'PUNCT': 5, 'ADP': 3, 'DET': 2, 'CCONJ': 1}\n",
      "{'NOUN': 1, 'ADP': 1, 'NUM': 1, 'SPACE': 1}\n",
      "{'PROPN': 1, 'SPACE': 2, 'ADP': 1, 'NUM': 1}\n",
      "{'NOUN': 1, 'SPACE': 2, 'ADP': 1, 'NUM': 1}\n",
      "{'NOUN': 7, 'PUNCT': 5, 'SCONJ': 1, 'ADV': 4, 'DET': 2, 'ADJ': 3, 'AUX': 1, 'VERB': 1, 'ADP': 1}\n",
      "{'PROPN': 12, 'PART': 1, 'ADJ': 1, 'NOUN': 1, 'PUNCT': 1, 'SPACE': 1}\n",
      "{'NUM': 1, 'PUNCT': 2, 'NOUN': 7, 'CCONJ': 1, 'SPACE': 1}\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,9):\n",
    "    sent1 = df['Text'].values[i]\n",
    "    doc1 = nlp(sent1)\n",
    "    token_list = []\n",
    "\n",
    "    for token in doc1:\n",
    "        token_list.append(token.pos_)\n",
    "    \n",
    "    pos_count = Counter(token_list)\n",
    "    dict_count = dict(pos_count)\n",
    "    print(dict_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-allowance",
   "metadata": {},
   "source": [
    "## Named Entities Recognition\n",
    "\n",
    "**Exercise 1.8**\n",
    "\n",
    "In the Twitter dataset sample above, count how many entities are in each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "smooth-chrome",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T06:19:13.644167Z",
     "start_time": "2021-03-31T06:19:13.559490Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-299-3da467851c10>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-299-3da467851c10>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    df[\"ents\"] = # your code here\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "df[\"ents\"] = # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "noticed-honor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T06:18:11.584150Z",
     "start_time": "2021-03-31T06:18:11.571558Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNTA Over 12.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OI  Over 21.37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PGNX  Over 3.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAP - user if so then the current downtrend wi...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Monday's relative weakness. NYX WIN TIE TAP IC...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GOOG - ower trend line channel test &amp; volume s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AAP will watch tomorrow for ONG entry.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment\n",
       "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1\n",
       "1  user: AAP MOVIE. 55% return for the FEA/GEED i...          1\n",
       "2  user I'd be afraid to short AMZN - they are lo...          1\n",
       "3                                  MNTA Over 12.00            1\n",
       "4                                   OI  Over 21.37            1\n",
       "5                                  PGNX  Over 3.04            1\n",
       "6  AAP - user if so then the current downtrend wi...         -1\n",
       "7  Monday's relative weakness. NYX WIN TIE TAP IC...         -1\n",
       "8  GOOG - ower trend line channel test & volume s...          1\n",
       "9             AAP will watch tomorrow for ONG entry.          1"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-method",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T06:18:48.877669Z",
     "start_time": "2021-03-31T06:18:48.859874Z"
    }
   },
   "source": [
    "**Exercise 1.9**\n",
    "\n",
    "In the Twitter dataset sample above, create an extra column with the name of the Organization entities in the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-accordance",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T06:20:28.240476Z",
     "start_time": "2021-03-31T06:20:28.227574Z"
    }
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "cubic-favor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T06:20:50.058745Z",
     "start_time": "2021-03-31T06:20:49.970719Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-301-646ed2b95133>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-301-646ed2b95133>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    df[\"Organizations\"] = # your code here\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "df[\"Organizations\"] = # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-monthly",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T06:20:51.522613Z",
     "start_time": "2021-03-31T06:20:51.500337Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-island",
   "metadata": {},
   "source": [
    "## Matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-guyana",
   "metadata": {},
   "source": [
    "**Exercise 2.0**\n",
    "\n",
    "You have scraped many websites collecting a list of users but written in many different form: someone has an email like:\n",
    "\n",
    "```\n",
    "username: antonio\n",
    "user: antonio.marsella@email.com\n",
    "USER:antonio\n",
    "USERNAME: antonio\n",
    "```\n",
    "How would you match all of them using a spaCy matcher?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "little-appendix",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "username: antonio\n",
    "user: antonio.marsella@email.com\n",
    "USER:antonio\n",
    "USERNAME: antonio\n",
    "\"\"\"\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "domestic-footage",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T06:48:55.806530Z",
     "start_time": "2021-03-31T06:48:55.729472Z"
    }
   },
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "pattern = [\n",
    "    #{'lower': 'username'},\n",
    "    {'lower': 'user'},\n",
    "    {'IS_PUNCT': True},\n",
    "    {'IS_SPACE': True, 'OP': '?'},\n",
    "    {'lower': 'antonio'},\n",
    "    {'IS_PUNCT': True, 'OP': '?'},\n",
    "    {'lower': 'marsella'}\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "three-ceiling",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"USERNAME\", [pattern])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "tender-variety",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(string_id, start, end, span.text)\n",
    "    \n",
    "#dir(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-speaker",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
