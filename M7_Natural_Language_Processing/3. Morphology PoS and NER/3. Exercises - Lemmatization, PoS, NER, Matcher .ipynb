{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "valid-consultation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T19:32:23.755820Z",
     "start_time": "2021-03-30T19:32:22.644310Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-mortgage",
   "metadata": {},
   "source": [
    "## Lemmatization\n",
    "\n",
    "**Exercise 1.1**\n",
    "\n",
    "You are given the words \"playing\", \"played\", \"play\". Find the lemma using spaCy for all of them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "english-plate",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T19:34:20.464484Z",
     "start_time": "2021-03-30T19:34:20.425793Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lemma of the word \"playing\" is play\n",
      "The lemma of the word \"played\" is play\n",
      "The lemma of the word \"playing\" is play\n"
     ]
    }
   ],
   "source": [
    "words = [\"playing\", \"played\", \"playing\"]\n",
    "\n",
    "for word in words:\n",
    "    nlp_word = nlp(word)\n",
    "    for i in nlp_word:\n",
    "        print(f'The lemma of the word \"{nlp_word.text}\" is {i.lemma_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-commonwealth",
   "metadata": {},
   "source": [
    "**Exercise 1.2**\n",
    "\n",
    "Assign the spaCy lemmatizer to a variable instead of using the whole `nlp` pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-damage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "clinical-champion",
   "metadata": {},
   "source": [
    "**Exercise 1.3**\n",
    "\n",
    "Find the verb, the noun and the adjective forms of the words: \"playing\", \"played\", \"surfing\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-blood",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T19:41:42.605031Z",
     "start_time": "2021-03-30T19:41:42.595092Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "documentary-heart",
   "metadata": {},
   "source": [
    "## Spell Checker\n",
    "\n",
    "**Exercise 1.4**\n",
    "\n",
    "In the following sentences there are some mispelling errors. Can you preprocess them to get rid of them? \n",
    "\n",
    "*N.B. there's no perfect spell-checker. Don't waste time on this. But be aware that it can be useful sometimes.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "caroline-agency",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T20:10:59.239954Z",
     "start_time": "2021-03-30T20:10:59.087475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i really like this exercise\n",
      "tis sentences are surely writer by an italian\n",
      "lets fix thissssss\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"i realy like this exerxise\", \n",
    "             \"tis sentences are surely writen by an italian\",\n",
    "             \"lets fix thissssss\"\n",
    "            ]\n",
    "\n",
    "from autocorrect import Speller\n",
    "\n",
    "spell = Speller()\n",
    "\n",
    "for i in sentences:\n",
    "    print(spell(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-imperial",
   "metadata": {},
   "source": [
    "## POS Tagging\n",
    "\n",
    "**Exercise 1.5 (★☆☆)**\n",
    "\n",
    "The training of TAs to survive the first two weeks at Strive School consists of the following sets:\n",
    "\n",
    "- 1000 reps of \"Did you google it?\"\n",
    "- 1000 reps of \"Did you search it on Google already?\"\n",
    "\n",
    "Use spaCy to explain the difference of the word \"google\" in the two sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "dried-tulsa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "respiratory-priest",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T04:57:52.063503Z",
     "start_time": "2021-03-31T04:57:51.819028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google -- VERB -- VB -- verb, base form\n",
      "Google -- PROPN -- NNP -- noun, proper singular\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"Did you google it?\",\n",
    "             \"Did you search it on Google already?\"]\n",
    "\n",
    "for sent in sentences:\n",
    "    nlp_sent = nlp(sent)\n",
    "    for word in nlp_sent:\n",
    "        if word.text.lower() == 'google':\n",
    "            print(f'{word} -- {word.pos_} -- {word.tag_} -- {spacy.explain(word.tag_)}')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-iceland",
   "metadata": {},
   "source": [
    "**Exercise 1.5 (★★☆)**\n",
    "\n",
    "Get the frequencies of the POS tags in the example sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "rational-xerox",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T05:17:13.245020Z",
     "start_time": "2021-03-31T05:17:13.220428Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'DET': 3,\n",
       "         'AUX': 1,\n",
       "         'NOUN': 3,\n",
       "         'PUNCT': 2,\n",
       "         'SPACE': 1,\n",
       "         'PROPN': 2,\n",
       "         'ADP': 1,\n",
       "         'PRON': 1})"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "sentence = \"\"\"This is an example sentence.\n",
    "            Count the POS tags in it.\"\"\"\n",
    "\n",
    "doc = nlp(sentence)\n",
    "\n",
    "token_list = []\n",
    "\n",
    "for token in doc:\n",
    "    token_list.append(token.pos_)\n",
    "    \n",
    "pos_count = Counter(token_list)\n",
    "pos_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-label",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T05:09:39.399233Z",
     "start_time": "2021-03-31T05:09:39.364673Z"
    }
   },
   "source": [
    "**Exercise 1.7 (★★★)**\n",
    "\n",
    "(This exercises requires many steps in Pandas, no unique solution. You can hard code the name of the columns for this example if you get stuck.)\n",
    "\n",
    "Loading 10 tweets from the twitter datasets, create a dataframe containing the frequencies of each POS per tweet (see example).\n",
    "\n",
    "N.B. The column names must be the tags not the indices of the tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "fifth-dispute",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T06:16:19.616337Z",
     "start_time": "2021-03-31T06:16:19.498649Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/stock_data.csv\")\n",
    "\n",
    "df = df.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "outstanding-commonwealth",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T06:16:19.660774Z",
     "start_time": "2021-03-31T06:16:19.656353Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNTA Over 12.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OI  Over 21.37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PGNX  Over 3.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAP - user if so then the current downtrend wi...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Monday's relative weakness. NYX WIN TIE TAP IC...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GOOG - ower trend line channel test &amp; volume s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AAP will watch tomorrow for ONG entry.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment\n",
       "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1\n",
       "1  user: AAP MOVIE. 55% return for the FEA/GEED i...          1\n",
       "2  user I'd be afraid to short AMZN - they are lo...          1\n",
       "3                                  MNTA Over 12.00            1\n",
       "4                                   OI  Over 21.37            1\n",
       "5                                  PGNX  Over 3.04            1\n",
       "6  AAP - user if so then the current downtrend wi...         -1\n",
       "7  Monday's relative weakness. NYX WIN TIE TAP IC...         -1\n",
       "8  GOOG - ower trend line channel test & volume s...          1\n",
       "9             AAP will watch tomorrow for ONG entry.          1"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "median-discrimination",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T05:26:12.875138Z",
     "start_time": "2021-03-31T05:26:12.865565Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_pos_and_frequency(sentence, tagger=nlp):\n",
    "    sentence = tagger(sentence)\n",
    "    num_pos = sentence.count_by(spacy.attrs.POS)\n",
    "    named_pos = {}\n",
    "    for k, v in num_pos.items():\n",
    "        named_pos[sentence.vocab[k].text] = v\n",
    "    return named_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "coordinated-olympus",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns = []\n",
    "for i, row in df.iterrows():\n",
    "    pos_dict = get_pos_and_frequency(row.Text)\n",
    "    for key in pos_dict.keys():\n",
    "        if key not in columns:\n",
    "            columns.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "banner-delaware",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "tropical-detective",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T05:34:45.822225Z",
     "start_time": "2021-03-31T05:34:45.814005Z"
    }
   },
   "outputs": [],
   "source": [
    "columns = ['NOUN',\n",
    " 'ADP',\n",
    " 'DET',\n",
    " 'PROPN',\n",
    " 'SPACE',\n",
    " 'NUM',\n",
    " 'CCONJ',\n",
    " 'PUNCT',\n",
    " 'VERB',\n",
    " 'SYM',\n",
    " 'ADV',\n",
    " 'PRON',\n",
    " 'AUX',\n",
    " 'ADJ',\n",
    " 'PART',\n",
    " 'SCONJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "collective-missouri",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T05:50:57.001480Z",
     "start_time": "2021-03-31T05:50:56.992453Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>ADP</th>\n",
       "      <th>DET</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>SPACE</th>\n",
       "      <th>NUM</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>VERB</th>\n",
       "      <th>SYM</th>\n",
       "      <th>ADV</th>\n",
       "      <th>PRON</th>\n",
       "      <th>AUX</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>PART</th>\n",
       "      <th>SCONJ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Text  NOUN  ADP  DET  PROPN  SPACE  NUM  CCONJ  PUNCT  VERB  SYM  ADV  \\\n",
       "0   0.0   0.0  0.0  0.0    0.0    0.0  0.0    0.0    0.0   0.0  0.0  0.0   \n",
       "1   0.0   0.0  0.0  0.0    0.0    0.0  0.0    0.0    0.0   0.0  0.0  0.0   \n",
       "2   0.0   0.0  0.0  0.0    0.0    0.0  0.0    0.0    0.0   0.0  0.0  0.0   \n",
       "3   0.0   0.0  0.0  0.0    0.0    0.0  0.0    0.0    0.0   0.0  0.0  0.0   \n",
       "4   0.0   0.0  0.0  0.0    0.0    0.0  0.0    0.0    0.0   0.0  0.0  0.0   \n",
       "5   0.0   0.0  0.0  0.0    0.0    0.0  0.0    0.0    0.0   0.0  0.0  0.0   \n",
       "6   0.0   0.0  0.0  0.0    0.0    0.0  0.0    0.0    0.0   0.0  0.0  0.0   \n",
       "7   0.0   0.0  0.0  0.0    0.0    0.0  0.0    0.0    0.0   0.0  0.0  0.0   \n",
       "8   0.0   0.0  0.0  0.0    0.0    0.0  0.0    0.0    0.0   0.0  0.0  0.0   \n",
       "9   0.0   0.0  0.0  0.0    0.0    0.0  0.0    0.0    0.0   0.0  0.0  0.0   \n",
       "\n",
       "   PRON  AUX  ADJ  PART  SCONJ  \n",
       "0   0.0  0.0  0.0   0.0    0.0  \n",
       "1   0.0  0.0  0.0   0.0    0.0  \n",
       "2   0.0  0.0  0.0   0.0    0.0  \n",
       "3   0.0  0.0  0.0   0.0    0.0  \n",
       "4   0.0  0.0  0.0   0.0    0.0  \n",
       "5   0.0  0.0  0.0   0.0    0.0  \n",
       "6   0.0  0.0  0.0   0.0    0.0  \n",
       "7   0.0  0.0  0.0   0.0    0.0  \n",
       "8   0.0  0.0  0.0   0.0    0.0  \n",
       "9   0.0  0.0  0.0   0.0    0.0  "
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "array = np.zeros((10,len(columns)+1))\n",
    "data = pd.DataFrame(array, columns=[\"Text\", *columns])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "rural-ceremony",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T05:50:57.385440Z",
     "start_time": "2021-03-31T05:50:57.369822Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NOUN': 7, 'ADP': 1, 'PRON': 1, 'PROPN': 7, 'SPACE': 1, 'NUM': 2, 'CCONJ': 1, 'PUNCT': 1, 'VERB': 1}\n",
      "{'NOUN': 6, 'PUNCT': 4, 'PROPN': 5, 'NUM': 2, 'ADP': 2, 'DET': 2, 'SYM': 1, 'ADV': 1, 'SPACE': 2}\n",
      "{'NOUN': 4, 'PRON': 2, 'AUX': 3, 'VERB': 2, 'ADJ': 3, 'PROPN': 2, 'PUNCT': 5, 'ADP': 3, 'DET': 2, 'CCONJ': 1}\n",
      "{'NOUN': 1, 'ADP': 1, 'NUM': 1, 'SPACE': 1}\n",
      "{'PROPN': 1, 'SPACE': 2, 'ADP': 1, 'NUM': 1}\n",
      "{'NOUN': 1, 'SPACE': 2, 'ADP': 1, 'NUM': 1}\n",
      "{'NOUN': 7, 'PUNCT': 5, 'SCONJ': 1, 'ADV': 4, 'DET': 2, 'ADJ': 3, 'AUX': 1, 'VERB': 1, 'ADP': 1}\n",
      "{'PROPN': 12, 'PART': 1, 'ADJ': 1, 'NOUN': 1, 'PUNCT': 1, 'SPACE': 1}\n",
      "{'NUM': 1, 'PUNCT': 2, 'NOUN': 7, 'CCONJ': 1, 'SPACE': 1}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "studied-myrtle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>ADP</th>\n",
       "      <th>DET</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>SPACE</th>\n",
       "      <th>NUM</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>VERB</th>\n",
       "      <th>SYM</th>\n",
       "      <th>ADV</th>\n",
       "      <th>PRON</th>\n",
       "      <th>AUX</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>PART</th>\n",
       "      <th>SCONJ</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>MNTA Over 12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>OI  Over 21.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PGNX  Over 3.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAP - user if so then the current downtrend wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Monday's relative weakness. NYX WIN TIE TAP IC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>GOOG - ower trend line channel test &amp; volume s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AAP will watch tomorrow for ONG entry.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Text  NOUN  ADP  DET  PROPN  SPACE  NUM  CCONJ  PUNCT  VERB  SYM  ADV  \\\n",
       "0   0.0   7.0  1.0  0.0    7.0    1.0  2.0    1.0    1.0   1.0  0.0  0.0   \n",
       "1   0.0   6.0  2.0  2.0    5.0    2.0  2.0    0.0    4.0   0.0  1.0  1.0   \n",
       "2   0.0   4.0  3.0  2.0    2.0    0.0  0.0    1.0    5.0   2.0  0.0  0.0   \n",
       "3   0.0   1.0  1.0  0.0    0.0    1.0  1.0    0.0    0.0   0.0  0.0  0.0   \n",
       "4   0.0   0.0  1.0  0.0    1.0    2.0  1.0    0.0    0.0   0.0  0.0  0.0   \n",
       "5   0.0   1.0  1.0  0.0    0.0    2.0  1.0    0.0    0.0   0.0  0.0  0.0   \n",
       "6   0.0   7.0  1.0  2.0    0.0    0.0  0.0    0.0    5.0   1.0  0.0  4.0   \n",
       "7   0.0   1.0  0.0  0.0   12.0    1.0  0.0    0.0    1.0   0.0  0.0  0.0   \n",
       "8   0.0   7.0  0.0  0.0    0.0    1.0  1.0    1.0    2.0   0.0  0.0  0.0   \n",
       "9   0.0   3.0  1.0  0.0    1.0    0.0  0.0    0.0    1.0   1.0  0.0  0.0   \n",
       "\n",
       "   PRON  AUX  ADJ  PART  SCONJ  \\\n",
       "0   1.0  0.0  0.0   0.0    0.0   \n",
       "1   0.0  0.0  0.0   0.0    0.0   \n",
       "2   2.0  3.0  3.0   0.0    0.0   \n",
       "3   0.0  0.0  0.0   0.0    0.0   \n",
       "4   0.0  0.0  0.0   0.0    0.0   \n",
       "5   0.0  0.0  0.0   0.0    0.0   \n",
       "6   0.0  1.0  3.0   0.0    1.0   \n",
       "7   0.0  0.0  1.0   1.0    0.0   \n",
       "8   0.0  0.0  0.0   0.0    0.0   \n",
       "9   0.0  1.0  0.0   0.0    0.0   \n",
       "\n",
       "                                                text  \n",
       "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...  \n",
       "1  user: AAP MOVIE. 55% return for the FEA/GEED i...  \n",
       "2  user I'd be afraid to short AMZN - they are lo...  \n",
       "3                                  MNTA Over 12.00    \n",
       "4                                   OI  Over 21.37    \n",
       "5                                  PGNX  Over 3.04    \n",
       "6  AAP - user if so then the current downtrend wi...  \n",
       "7  Monday's relative weakness. NYX WIN TIE TAP IC...  \n",
       "8  GOOG - ower trend line channel test & volume s...  \n",
       "9             AAP will watch tomorrow for ONG entry.  "
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, row in df.iterrows():\n",
    "    pos_dict = get_pos_and_frequency(row.Text)\n",
    "    for key, value in pos_dict.items():\n",
    "        data.loc[i, key] = value\n",
    "    data.loc[i, \"text\"] = row.Text\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-allowance",
   "metadata": {},
   "source": [
    "## Named Entities Recognition\n",
    "\n",
    "**Exercise 1.8**\n",
    "\n",
    "In the Twitter dataset sample above, count how many entities are in each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "smooth-chrome",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T06:19:13.644167Z",
     "start_time": "2021-03-31T06:19:13.559490Z"
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "def count_ents(sentence, ner=nlp):\n",
    "    sentence = ner(sentence)\n",
    "    return len(sentence.ents)\n",
    "\n",
    "df[\"ents\"] = df.Text.apply(count_ents)# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "noticed-honor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T06:18:11.584150Z",
     "start_time": "2021-03-31T06:18:11.571558Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>ents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNTA Over 12.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OI  Over 21.37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PGNX  Over 3.04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAP - user if so then the current downtrend wi...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Monday's relative weakness. NYX WIN TIE TAP IC...</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GOOG - ower trend line channel test &amp; volume s...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AAP will watch tomorrow for ONG entry.</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment  ents\n",
       "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1     4\n",
       "1  user: AAP MOVIE. 55% return for the FEA/GEED i...          1     4\n",
       "2  user I'd be afraid to short AMZN - they are lo...          1     2\n",
       "3                                  MNTA Over 12.00            1     2\n",
       "4                                   OI  Over 21.37            1     0\n",
       "5                                  PGNX  Over 3.04            1     1\n",
       "6  AAP - user if so then the current downtrend wi...         -1     0\n",
       "7  Monday's relative weakness. NYX WIN TIE TAP IC...         -1     3\n",
       "8  GOOG - ower trend line channel test & volume s...          1     0\n",
       "9             AAP will watch tomorrow for ONG entry.          1     2"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-method",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T06:18:48.877669Z",
     "start_time": "2021-03-31T06:18:48.859874Z"
    }
   },
   "source": [
    "**Exercise 1.9**\n",
    "\n",
    "In the Twitter dataset sample above, create an extra column with the name of the Organization entities in the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "ceramic-accordance",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T06:20:28.240476Z",
     "start_time": "2021-03-31T06:20:28.227574Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_ents(sentence, ner=nlp):\n",
    "    sentence = ner(sentence)\n",
    "    return sentence.ents\n",
    "\n",
    "def get_orgs(sentence, ner=nlp):\n",
    "    ents = get_ents(sentence, ner=ner)\n",
    "    return [ent.text for ent in ents if ent.label_==\"ORG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "cubic-favor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T06:20:50.058745Z",
     "start_time": "2021-03-31T06:20:49.970719Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"Organizations\"] = df.Text.apply(get_orgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "illegal-monthly",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-31T06:20:51.522613Z",
     "start_time": "2021-03-31T06:20:51.500337Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>ents</th>\n",
       "      <th>Organizations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[PNK]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[AWESOME]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[AMZN, eBooks]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNTA Over 12.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OI  Over 21.37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PGNX  Over 3.04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[PGNX]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAP - user if so then the current downtrend wi...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Monday's relative weakness. NYX WIN TIE TAP IC...</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>[NYX WIN TIE TAP ICE INT BMC, CHK BIIB]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GOOG - ower trend line channel test &amp; volume s...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AAP will watch tomorrow for ONG entry.</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[ONG]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment  ents  \\\n",
       "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1     4   \n",
       "1  user: AAP MOVIE. 55% return for the FEA/GEED i...          1     4   \n",
       "2  user I'd be afraid to short AMZN - they are lo...          1     2   \n",
       "3                                  MNTA Over 12.00            1     2   \n",
       "4                                   OI  Over 21.37            1     0   \n",
       "5                                  PGNX  Over 3.04            1     1   \n",
       "6  AAP - user if so then the current downtrend wi...         -1     0   \n",
       "7  Monday's relative weakness. NYX WIN TIE TAP IC...         -1     3   \n",
       "8  GOOG - ower trend line channel test & volume s...          1     0   \n",
       "9             AAP will watch tomorrow for ONG entry.          1     2   \n",
       "\n",
       "                             Organizations  \n",
       "0                                    [PNK]  \n",
       "1                                [AWESOME]  \n",
       "2                           [AMZN, eBooks]  \n",
       "3                                       []  \n",
       "4                                       []  \n",
       "5                                   [PGNX]  \n",
       "6                                       []  \n",
       "7  [NYX WIN TIE TAP ICE INT BMC, CHK BIIB]  \n",
       "8                                       []  \n",
       "9                                    [ONG]  "
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-island",
   "metadata": {},
   "source": [
    "## Matcher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-guyana",
   "metadata": {},
   "source": [
    "**Exercise 2.0**\n",
    "\n",
    "You have scraped many websites collecting a list of users but written in many different form: someone has an email like:\n",
    "\n",
    "```\n",
    "username: antonio\n",
    "user: antonio.marsella@email.com\n",
    "USER:antonio\n",
    "USERNAME: antonio\n",
    "```\n",
    "How would you match all of them using a spaCy matcher?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "little-appendix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USERNAME 1 4 username: antonio\n",
      "USERNAME 5 8 user: antonio.marsella@email.com\n",
      "USERNAME 9 12 USER:antonio\n",
      "USERNAME 13 16 USERNAME: antonio\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "username: antonio\n",
    "user: antonio.marsella@email.com\n",
    "USER:antonio\n",
    "USERNAME: antonio\n",
    "\"\"\"\n",
    "\n",
    "pattern = [{\"LOWER\": {\"IN\":[\"user\",\"username\"]}}, {\"ORTH\": \":\"}, {}]\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"USERNAME\", [pattern])\n",
    "\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-speaker",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
