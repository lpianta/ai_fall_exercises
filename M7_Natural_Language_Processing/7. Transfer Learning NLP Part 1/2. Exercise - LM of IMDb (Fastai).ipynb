{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune a Langage Model with Fast.ai\n",
    "Notebook based on:\n",
    "- https://github.com/fastai/fastbook/blob/master/10_nlp.ipynb\n",
    "- https://github.com/fastai/course-nlp/blob/master/5-nn-imdb.ipynb\n",
    "\n",
    "Video:\n",
    "- https://www.youtube.com/watch?v=WjnwWeGjZcM (From 0:00 to 55:00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get latest Fast.ai version (without installing the Pytorch dependency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: fastai in /home/javi/.local/lib/python3.9/site-packages (2.3.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: fastcore in /home/javi/.local/lib/python3.9/site-packages (1.3.19)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --no-deps fastai\n",
    "!pip install --upgrade --no-deps fastcore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.all import * # We need fastai version 2 for this\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check GPU usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"WARNING: Not GPU detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLOUD = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is loacted at: ../../Datasets/NLP/IMBd\n"
     ]
    }
   ],
   "source": [
    "if CLOUD:\n",
    "    # Download the data from internet\n",
    "    # If you are using cloud platforms\n",
    "    # like Google Colab or Kaggle kernels\n",
    "    data_path = untar_data(URLs.IMDB)\n",
    "else:\n",
    "    # Point to the path where the data is\n",
    "    # located at your local machine\n",
    "    data_path = Path(\"../../Datasets/NLP/IMBd\")\n",
    "    \n",
    "print(\"Dataset is loacted at:\", data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 25000 reviews\n",
      "Test:  25000 reviews\n",
      "Unsup: 50000 reviews\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\", len(list( (data_path/\"train\").glob('**/*.txt') )), \"reviews\")\n",
    "print(\"Test: \", len(list( (data_path/\"test\").glob('**/*.txt')  )), \"reviews\")\n",
    "print(\"Unsup:\", len(list( (data_path/\"unsup\").glob('**/*.txt') )), \"reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#100000) [Path('../../Datasets/NLP/IMBd/test/pos/5249_9.txt'),Path('../../Datasets/NLP/IMBd/test/pos/10762_9.txt'),Path('../../Datasets/NLP/IMBd/test/pos/7600_8.txt'),Path('../../Datasets/NLP/IMBd/test/pos/8226_9.txt'),Path('../../Datasets/NLP/IMBd/test/pos/6211_8.txt'),Path('../../Datasets/NLP/IMBd/test/pos/3056_9.txt'),Path('../../Datasets/NLP/IMBd/test/pos/20_9.txt'),Path('../../Datasets/NLP/IMBd/test/pos/1368_8.txt'),Path('../../Datasets/NLP/IMBd/test/pos/4866_7.txt'),Path('../../Datasets/NLP/IMBd/test/pos/3370_7.txt')...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = get_text_files(data_path, folders = ['train', 'test', 'unsup'])\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is an extraordinary film musically. It made me feel awful that Rodrigu'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = files[0].open().read()\n",
    "txt[:75]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader\n",
    "\n",
    "At every epoch:\n",
    "\n",
    "1. **Shuffle** (sort randomly) our collection of texts.\n",
    "2. **Concatenate** the individual texts together into a big stream. \n",
    "3. **Cut** this stream into a certain number of batches (which is our batch size).\n",
    "   - For instance, if the stream has 50,000 tokens and we set a batch size of 10, this will give us 10 mini-streams of 5,000 tokens.\n",
    "   \n",
    "So to recap, at every epoch we shuffle our collection of documents and concatenate them into a stream of tokens. We then cut that stream into a batch of fixed-size consecutive mini-streams. Our model will then read the mini-streams in order, and thanks to an inner state, it will produce the same activation whatever sequence length we picked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- takes 5 mins for tokenization in Kaggle\n",
    "- takes 1 mins for tokenization in local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_imdb = partial(get_text_files, folders=['train', 'test', 'unsup'])\n",
    "\n",
    "imdb_dls_lm = DataBlock(\n",
    "    blocks    = TextBlock.from_folder(data_path, is_lm=True),\n",
    "    get_items = get_imdb,\n",
    "    splitter  = RandomSplitter(0.1)\n",
    ").dataloaders(data_path, path=data_path, bs=128, seq_len=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos i was true to my regard for xxmaj mr . xxmaj glover and xxmaj ms . xxmaj goldberg . i watched the entire film with my family and some friends . i have no idea what the movie was about . xxmaj after much discussion , we all agreed that this was not one of their better efforts . \\n\\n xxmaj it does n't hang together very well . xxmaj it is too choppy , and there is little</td>\n",
       "      <td>i was true to my regard for xxmaj mr . xxmaj glover and xxmaj ms . xxmaj goldberg . i watched the entire film with my family and some friends . i have no idea what the movie was about . xxmaj after much discussion , we all agreed that this was not one of their better efforts . \\n\\n xxmaj it does n't hang together very well . xxmaj it is too choppy , and there is little comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to the second question ; what is with all the personal objects ( mobile phones , cars , clothes ) of the dead people ? xxmaj using their third brother as a connection with the exterior , it 's pretty much arguable that the xxmaj sinclair twins should obtain the money necessary to buy the wax , in a wwii - type fashion . \\n\\n xxmaj so , that aside , i think the movie deserves a lot more than</td>\n",
       "      <td>the second question ; what is with all the personal objects ( mobile phones , cars , clothes ) of the dead people ? xxmaj using their third brother as a connection with the exterior , it 's pretty much arguable that the xxmaj sinclair twins should obtain the money necessary to buy the wax , in a wwii - type fashion . \\n\\n xxmaj so , that aside , i think the movie deserves a lot more than it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imdb_dls_lm.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xxunk', 'xxpad', 'xxbos', 'xxeos', 'xxfld', 'xxrep', 'xxwrep', 'xxup', 'xxmaj', 'the', '.', ',', 'and', 'a', 'of', 'to', 'is', 'it', 'in', 'i', 'this', 'that', '\"', \"'s\", '-', 'was', '\\n\\n', 'as', 'with', 'for', 'movie', 'but', 'film', 'you', ')', 'on', \"n't\", '(', 'not', 'are', 'he', 'his', 'have', 'be', 'one', 'all', 'at', 'they', 'by', 'an', 'who', 'from', 'so', 'like', '!', 'there', 'or', 'just', 'her', 'do', 'about', 'has', 'out', \"'\", 'if', 'what', 'some', '?', 'good', 'when', 'more', 'very', 'she', 'up', 'would', 'no', '…', 'time', 'even', 'my', 'can', 'their', 'which', 'only', 'story', 'really', 'see', 'had', 'were', 'did', 'me', 'well', 'we', 'does', 'than', 'much', ':', 'could', 'bad', 'get']\n"
     ]
    }
   ],
   "source": [
    "print(imdb_dls_lm.vocab[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60008"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imdb_dls_lm.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Fastai learner (dataloader + model + loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = language_model_learner(\n",
    "    dls       = imdb_dls_lm,\n",
    "    arch      = AWD_LSTM,\n",
    "    drop_mult = 0.3, \n",
    "    metrics   = [accuracy, Perplexity()],\n",
    "    cbs       = [ShowGraphCallback]\n",
    ").to_fp16()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Generation BEFORE FINETUNNNG WITH IMDB (Just for fun :D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The American Civil War = of a Civil War , NATO - occupied , NATO territory between France and Spain , Spain and Spain , was fought during the\n",
      "\n",
      "The Take Over ( Martin Luther King Award show ) 1963 , New York , New York , USA , bogs , TV , and TV ,\n",
      "\n",
      "The String Quartet Quartet ( 2007 – 08 ) = , also known as the Trio , is a small orchestral concert series by Trio that includes the jazz - inspired works of Richard\n",
      "\n",
      "The Magnus Reloaded ( 2008 ) album = = = The Greatest Hits Vol . 2 ( 2009 ) . The Swedish Armed Forces and Swedish Forces Germany\n",
      "\n",
      "The Ford Blues = = a Blues Blues , formally named Ford Blues , was founded in 1951 . The Ford Club , the oldest \" folk club of Ford 's\n"
     ]
    }
   ],
   "source": [
    "TEXT        = \"The\"\n",
    "N_WORDS     = 40\n",
    "N_SENTENCES = 5\n",
    "\n",
    "preds = [learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)]\n",
    "\n",
    "print(\"\\n\\n\".join(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning the Language Model with IMDB\n",
    "- This takes 24:46 mins on GTX 1080ti 11GB\n",
    "- This takes 27:48 mins on Tesla P100 16GB (Kaggle GPU)\n",
    "- This takes ~22mins mins on Tesla T4 (Colab GPU)\n",
    "- This takes >30mins mins on Tesla K80 (Colab GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.016691</td>\n",
       "      <td>3.910882</td>\n",
       "      <td>0.299828</td>\n",
       "      <td>49.942993</td>\n",
       "      <td>24:46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 2e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Loading Models\n",
    "You can easily save the state of your model like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('IMDb_LM_1epoch_frozen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('../../Datasets/NLP/IMBd')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will create a file in `learn.path/models/` named *IMDb_LM_1epoch_frozen.pth*. If you want to load your model in another machine after creating your `Learner` the same way, or resume training later, you can load the content of this file with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load('IMDb_LM_1epoch_frozen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the initial training has completed, we can continue fine-tuning the model after unfreezing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(10, 2e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once this is done, we save all of our model except the final layer that converts activations to probabilities of picking each token in our vocabulary. The model not including the final layer is called the *encoder*. We can save it with `save_encoder`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder('finetuned_IMDb_LM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> jargon: Encoder: The model not including the task-specific final layer(s). This term means much the same thing as _body_ when applied to vision CNNs, but \"encoder\" tends to be more used for NLP and generative models.\n",
    "\n",
    "This completes the second stage of the text classification process: fine-tuning the language model. We can now use it to fine-tune a classifier using the IMDb sentiment labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Generation AFTER FINETUNNNG WITH IMDB (Just for fun :D)\n",
    "Before we move on to fine-tuning the classifier, let's quickly try something different: using our model to generate random reviews. Since it's trained to guess what the next word of the sentence is, we can use the model to write new reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT        = \"The\"\n",
    "N_WORDS     = 40\n",
    "N_SENTENCES = 5\n",
    "\n",
    "preds = [learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)]\n",
    "\n",
    "print(\"\\n\\n\".join(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i liked this movie because of its similarity to the Emmy Award - winning film , The Godfather . The film 's two main characters , Elliot ( Dennis Medal ) and Benjamin ( George\n",
      "\n",
      "i liked this movie because it was \" a small , funny , open - air show , \" and \" like a movie that 's really funny \" , Succinct noted : \" To what 's going on , i needed a\n",
      "\n",
      "i liked this movie because it was a \" huge film \" . Although he made a good deal of treehouse films , he did not like the idea that the movie was going to be a big success . In an interview\n",
      "\n",
      "i liked this movie because of the \" a [ sic ] well [ depicted ] story \" . The film received positive reviews from critics , who praised the production of the film as well as the acting , though Brian\n",
      "\n",
      "i liked this movie because it was a movie , and he took it on a \" detailed \" basis . He described the film as a \" tremendous steel video \" of a character he had \" never seen before \" .\n"
     ]
    }
   ],
   "source": [
    "TEXT        = \"I liked this movie because\"\n",
    "N_WORDS     = 40\n",
    "N_SENTENCES = 5\n",
    "\n",
    "preds = [learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)]\n",
    "\n",
    "print(\"\\n\\n\".join(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we add some randomness (we pick a random word based on the probabilities returned by the model) so we don't get exactly the same review twice. Our model doesn't have any programmed knowledge of the structure of a sentence or grammar rules, yet it has clearly learned a lot about English sentences: we can see it capitalizes properly (*I* is just transformed to *i* because our rules require two characters or more to consider a word as capitalized, so it's normal to see it lowercased) and is using consistent tense. The general review makes sense at first glance, and it's only if you read carefully that you can notice something is a bit off. Not bad for a model trained in a couple of hours! \n",
    "\n",
    "But our end goal wasn't to train a model to generate reviews, but to classify them... so let's use this model to do just that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> END\n",
    "<center> We have fintuned the Language Model with the IMDb dataset.\n",
    "<center> The next step is using that model to train a classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
