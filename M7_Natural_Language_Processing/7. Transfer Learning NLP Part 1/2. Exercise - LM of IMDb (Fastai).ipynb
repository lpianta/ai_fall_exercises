{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "colab": {
      "name": "2. Exercise - LM of IMDb (Fastai).ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPL33FHr4C5v"
      },
      "source": [
        "# Finetune a Langage Model with Fast.ai\n",
        "Notebook based on:\n",
        "- https://github.com/fastai/fastbook/blob/master/10_nlp.ipynb\n",
        "- https://github.com/fastai/course-nlp/blob/master/5-nn-imdb.ipynb\n",
        "\n",
        "Video:\n",
        "- https://www.youtube.com/watch?v=WjnwWeGjZcM (From 0:00 to 55:00)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFrINySs4C56"
      },
      "source": [
        "#### Get latest Fast.ai version (without installing the Pytorch dependency)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nVX7G6Q4C57",
        "outputId": "325a3a11-2b82-4132-f362-c08bd064e12a"
      },
      "source": [
        "!pip install --upgrade --no-deps fastai\n",
        "!pip install --upgrade --no-deps fastcore"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: fastai in /usr/local/lib/python3.7/dist-packages (2.3.0)\n",
            "Requirement already up-to-date: fastcore in /usr/local/lib/python3.7/dist-packages (1.3.19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVZbRjMj4C5-"
      },
      "source": [
        "#### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYSJhRMb4C5-"
      },
      "source": [
        "from fastai.text.all import * # We need fastai version 2 for this\n",
        "from pathlib import Path"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpLDb0164C5-"
      },
      "source": [
        "#### Check GPU usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zf4F1acF4C5_",
        "outputId": "d03e2af1-88f5-4bc7-8624-37d01b5d6eb6"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"WARNING: Not GPU detected\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using GPU: Tesla K80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5V2SNny4C6A"
      },
      "source": [
        "# Get data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybIFkwJi4C6B"
      },
      "source": [
        "CLOUD = True"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gDh_klq4C6B",
        "outputId": "6afd4b9d-c874-4071-e508-7a90e846b77d"
      },
      "source": [
        "if CLOUD:\n",
        "    # Download the data from internet\n",
        "    # If you are using cloud platforms\n",
        "    # like Google Colab or Kaggle kernels\n",
        "    data_path = untar_data(URLs.IMDB)\n",
        "else:\n",
        "    # Point to the path where the data is\n",
        "    # located at your local machine\n",
        "    data_path = Path(\"../../Datasets/NLP/IMBd\")\n",
        "    \n",
        "print(\"Dataset is loacted at:\", data_path)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset is loacted at: /root/.fastai/data/imdb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8NqSseF4C6C",
        "outputId": "4a3551e4-3c20-4a6a-92af-45716cb351d0"
      },
      "source": [
        "print(\"Train:\", len(list( (data_path/\"train\").glob('**/*.txt') )), \"reviews\")\n",
        "print(\"Test: \", len(list( (data_path/\"test\").glob('**/*.txt')  )), \"reviews\")\n",
        "print(\"Unsup:\", len(list( (data_path/\"unsup\").glob('**/*.txt') )), \"reviews\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: 25000 reviews\n",
            "Test:  25000 reviews\n",
            "Unsup: 50000 reviews\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFvAz8eL4C6E"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOvdH7p_4C6E",
        "outputId": "53630d24-5410-4e0a-8c92-88e7f49ee86d"
      },
      "source": [
        "files = get_text_files(data_path, folders = ['train', 'test', 'unsup'])\n",
        "files"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#100000) [Path('/root/.fastai/data/imdb/train/neg/11850_3.txt'),Path('/root/.fastai/data/imdb/train/neg/11981_4.txt'),Path('/root/.fastai/data/imdb/train/neg/7924_1.txt'),Path('/root/.fastai/data/imdb/train/neg/6308_1.txt'),Path('/root/.fastai/data/imdb/train/neg/5460_4.txt'),Path('/root/.fastai/data/imdb/train/neg/284_2.txt'),Path('/root/.fastai/data/imdb/train/neg/11313_3.txt'),Path('/root/.fastai/data/imdb/train/neg/919_1.txt'),Path('/root/.fastai/data/imdb/train/neg/35_3.txt'),Path('/root/.fastai/data/imdb/train/neg/5452_4.txt')...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "cpS20_m_4C6F",
        "outputId": "7e35ec43-0ced-4a4a-f667-1638e8274121"
      },
      "source": [
        "txt = files[0].open().read()\n",
        "txt[:75]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"Rival reporters Pat Morgan (Ginger Rogers) and Ted Rand (Lyle Talbot) are '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9p4EjSn4C6F"
      },
      "source": [
        "## Dataloader\n",
        "\n",
        "At every epoch:\n",
        "\n",
        "1. **Shuffle** (sort randomly) our collection of texts.\n",
        "2. **Concatenate** the individual texts together into a big stream. \n",
        "3. **Cut** this stream into a certain number of batches (which is our batch size).\n",
        "   - For instance, if the stream has 50,000 tokens and we set a batch size of 10, this will give us 10 mini-streams of 5,000 tokens.\n",
        "   \n",
        "So to recap, at every epoch we shuffle our collection of documents and concatenate them into a stream of tokens. We then cut that stream into a batch of fixed-size consecutive mini-streams. Our model will then read the mini-streams in order, and thanks to an inner state, it will produce the same activation whatever sequence length we picked."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yamyl5Ym4C6F"
      },
      "source": [
        "- takes 5 mins for tokenization in Kaggle\n",
        "- takes 1 mins for tokenization in local machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPhF9Tl-4C6G"
      },
      "source": [
        "get_imdb = partial(get_text_files, folders=['train', 'test', 'unsup'])\n",
        "\n",
        "imdb_dls_lm = DataBlock(\n",
        "    blocks    = TextBlock.from_folder(data_path, is_lm=True),\n",
        "    get_items = get_imdb,\n",
        "    splitter  = RandomSplitter(0.1)\n",
        ").dataloaders(data_path, path=data_path, bs=128, seq_len=80)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "ZA_o8hGx4C6G",
        "outputId": "1b95c387-e243-4ed1-abe8-45b59f69c04f"
      },
      "source": [
        "imdb_dls_lm.show_batch(max_n=2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xxbos xxmaj oh , that was a really bad film . i like sci - fi very much , but this one … this is not sci - fi , this is a low - budget , low - story , low - acting \" low - film \" . xxmaj during watching the film i was waiting for something good , a good scene , a new idea , or … something . xxmaj unfortunately the end credits came</td>\n",
              "      <td>xxmaj oh , that was a really bad film . i like sci - fi very much , but this one … this is not sci - fi , this is a low - budget , low - story , low - acting \" low - film \" . xxmaj during watching the film i was waiting for something good , a good scene , a new idea , or … something . xxmaj unfortunately the end credits came before</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>of course that one important person on the plane , and the hijacker looking for revenge . xxmaj the sad thing is , some of the methods to stop the hijackers have already been used in other movies . xxmaj are we really becoming so unoriginal so quickly ? \\n\\n xxmaj although it 's ice - t ( who for some incomprehensible reason makes painful attempts at xxup acting while he 's not busy putting the \" c \" back</td>\n",
              "      <td>course that one important person on the plane , and the hijacker looking for revenge . xxmaj the sad thing is , some of the methods to stop the hijackers have already been used in other movies . xxmaj are we really becoming so unoriginal so quickly ? \\n\\n xxmaj although it 's ice - t ( who for some incomprehensible reason makes painful attempts at xxup acting while he 's not busy putting the \" c \" back in</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjGsGmAz4C6H",
        "outputId": "e47f07ca-ec55-4f9a-e816-4913fd1f050e"
      },
      "source": [
        "print(imdb_dls_lm.vocab[:100])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['xxunk', 'xxpad', 'xxbos', 'xxeos', 'xxfld', 'xxrep', 'xxwrep', 'xxup', 'xxmaj', 'the', '.', ',', 'and', 'a', 'of', 'to', 'is', 'it', 'in', 'i', 'this', 'that', '\"', \"'s\", '-', 'was', '\\n\\n', 'as', 'with', 'for', 'movie', 'but', 'film', 'you', ')', 'on', \"n't\", '(', 'not', 'are', 'he', 'his', 'have', 'be', 'one', 'all', 'at', 'they', 'by', 'an', 'who', 'from', 'so', 'like', '!', 'there', 'or', 'just', 'her', 'do', 'about', 'has', 'out', \"'\", 'if', 'what', 'some', '?', 'good', 'when', 'more', 'very', 'she', 'up', 'would', 'no', '…', 'time', 'even', 'my', 'can', 'their', 'which', 'only', 'story', 'really', 'see', 'had', 'were', 'did', 'me', 'well', 'we', 'does', 'than', 'much', ':', 'could', 'bad', 'get']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a40RRNeE4C6H",
        "outputId": "b6b6c3e2-0142-4acc-df01-e8e1be8ad29c"
      },
      "source": [
        "len(imdb_dls_lm.vocab)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60008"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lreKW3RB4C6H"
      },
      "source": [
        "# Create the Fastai learner (dataloader + model + loss)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_f_Ep1c4C6I"
      },
      "source": [
        "learn = language_model_learner(\n",
        "    dls       = imdb_dls_lm,\n",
        "    arch      = AWD_LSTM,\n",
        "    drop_mult = 0.3, \n",
        "    metrics   = [accuracy, Perplexity()],\n",
        "    cbs       = [ShowGraphCallback]\n",
        ").to_fp16()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jObNmCd4C6I"
      },
      "source": [
        "### Text Generation BEFORE FINETUNNNG WITH IMDB (Just for fun :D)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "-n54l5VV4C6I",
        "outputId": "70992898-9167-4219-b0ac-6b4bf71610e6"
      },
      "source": [
        "TEXT        = \"The\"\n",
        "N_WORDS     = 40\n",
        "N_SENTENCES = 5\n",
        "\n",
        "preds = [learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)]\n",
        "\n",
        "print(\"\\n\\n\".join(preds))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "The 30th Anniversary of Elizabeth 's Final Victory version of the episode , aired on December 29 , 2007 , the episode was broadcast on February 21 , 2007 . An episode of the\n",
            "\n",
            "The German invasion of the German Empire = The German Empire was a breakaway of the states who had entered the war . The German Empire ( German : \"\n",
            "\n",
            "The Film Festival of New York , Australia , October 21 – 26 , 1998 , Sydney , Australia , New Zealand , Canada , and the United\n",
            "\n",
            "The Rigsby Siege = = bread The Siege of Affections is a children 's novel by David Lean , written and published in 2010 by Brigham Young University . It\n",
            "\n",
            "The Cleveland Browns game play - by - play author , Cleveland , Ohio , National Football League Hall of Fame All - Star , and Cleveland Browns\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfucPwfJ4C6J"
      },
      "source": [
        "## Fine-Tuning the Language Model with IMDB\n",
        "- This takes 24:46 mins on GTX 1080ti 11GB\n",
        "- This takes 27:48 mins on Tesla P100 16GB (Kaggle GPU)\n",
        "- This takes ~22mins mins on Tesla T4 (Colab GPU)\n",
        "- This takes >30mins mins on Tesla K80 (Colab GPU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "r9F32YzT4C6J",
        "outputId": "927634ac-b072-4328-9cbb-e80c7fc9fdac"
      },
      "source": [
        "learn.fit_one_cycle(1, 2e-2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.034411</td>\n",
              "      <td>3.924759</td>\n",
              "      <td>0.299196</td>\n",
              "      <td>50.640854</td>\n",
              "      <td>2:00:51</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwyH0c7m4C6K"
      },
      "source": [
        "### Saving and Loading Models\n",
        "You can easily save the state of your model like so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Kcv4XrK4C6K",
        "outputId": "7ef38083-42cb-48e0-d073-3791be7e4757"
      },
      "source": [
        "learn.save('IMDb_LM_1epoch_frozen')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('/root/.fastai/data/imdb/models/IMDb_LM_1epoch_frozen.pth')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3Qlrsod4C6K",
        "outputId": "1cd34a8f-6b6c-4334-ea90-c0921fae8bb1"
      },
      "source": [
        "learn.path"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('/root/.fastai/data/imdb')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_XmWW4f4C6K"
      },
      "source": [
        "This will create a file in `learn.path/models/` named *IMDb_LM_1epoch_frozen.pth*. If you want to load your model in another machine after creating your `Learner` the same way, or resume training later, you can load the content of this file with:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUE0CJGW4C6L"
      },
      "source": [
        "learn = learn.load('IMDb_LM_1epoch_frozen')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBsc8RH54C6L"
      },
      "source": [
        "Once the initial training has completed, we can continue fine-tuning the model after unfreezing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "p9e9ml_J4C6L",
        "outputId": "c8e9e2dd-aa97-43b0-8239-a0b5cf4c900c"
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(10, 2e-3)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/10 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='10' class='' max='5262' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.19% [10/5262 00:15<2:13:38 3.8938]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-a21773809809>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/callback/schedule.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    110\u001b[0m     scheds = {'lr': combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final),\n\u001b[1;32m    111\u001b[0m               'mom': combined_cos(pct_start, *(self.moms if moms is None else moms))}\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mParamScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscheds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_hypers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelFitException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_end_cleanup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_end_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mb_on_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_on_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_one_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelBatchException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'before_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_cancel_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'after_{event_type}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mfinal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/learner.py\u001b[0m in \u001b[0;36m_do_one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'before_backward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'step'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCancelStepException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m                 inputs=inputs)\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/overrides.py\u001b[0m in \u001b[0;36mhandle_torch_function\u001b[0;34m(public_api, relevant_args, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0;31m# Use `public_api` instead of `implementation` so __torch_function__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m         \u001b[0;31m# implementations can do equality/identity comparisons.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1202\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moverloaded_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__torch_function__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpublic_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastai/torch_core.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_torch_handled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__torch_function__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_copy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisableTorchFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    963\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YqOomcU4C6L"
      },
      "source": [
        "Once this is done, we save all of our model except the final layer that converts activations to probabilities of picking each token in our vocabulary. The model not including the final layer is called the *encoder*. We can save it with `save_encoder`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEhvHoJ24C6L"
      },
      "source": [
        "learn.save_encoder('finetuned_IMDb_LM')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnadf0Cg4C6L"
      },
      "source": [
        "> jargon: Encoder: The model not including the task-specific final layer(s). This term means much the same thing as _body_ when applied to vision CNNs, but \"encoder\" tends to be more used for NLP and generative models.\n",
        "\n",
        "This completes the second stage of the text classification process: fine-tuning the language model. We can now use it to fine-tune a classifier using the IMDb sentiment labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6rZmaFv4C6L"
      },
      "source": [
        "### Text Generation AFTER FINETUNNNG WITH IMDB (Just for fun :D)\n",
        "Before we move on to fine-tuning the classifier, let's quickly try something different: using our model to generate random reviews. Since it's trained to guess what the next word of the sentence is, we can use the model to write new reviews:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "ON4HvZBW4C6M",
        "outputId": "1b7d50c1-01a4-495b-c9a9-646a6627bd38"
      },
      "source": [
        "TEXT        = \"The\"\n",
        "N_WORDS     = 40\n",
        "N_SENTENCES = 5\n",
        "\n",
        "preds = [learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)]\n",
        "\n",
        "print(\"\\n\\n\".join(preds))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "The Wicker Man is a great movie based on THE JULIAN Line with a executed script . It has a very good plot and a fairly bad ending . This movie does n't have\n",
            "\n",
            "The film was shot in a studio , which was shot in black and white , shot in a studio lens . Half - way through the film it is filmed with black and white camera shots of two and\n",
            "\n",
            "The first movie of the series is a little bit too predictable . The remake of the original CRUEL ROBIN HOOD is quite a little too long to find . However , the original was daring\n",
            "\n",
            "The first movie of the movie , Manos , Hands , Notes First , did n't go into theaters . The first movie was \" The Slave of the City \" , and\n",
            "\n",
            "The Dalton Brothers play in the works of David Niven and Alec Guinness . \n",
            "\n",
            " The show is very well done in Britain by one reviewer . The lead actor of the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "l-oThWId4C6M",
        "outputId": "b1e2ac1b-bde6-44c6-815b-b97b6512f631"
      },
      "source": [
        "TEXT        = \"I liked this movie because\"\n",
        "N_WORDS     = 40\n",
        "N_SENTENCES = 5\n",
        "\n",
        "preds = [learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)]\n",
        "\n",
        "print(\"\\n\\n\".join(preds))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "i liked this movie because it was very touching and sad , and it was so rare , and i think that all this movie is really a great movie . It 's brilliant and i do n't think it 's really entertaining .\n",
            "\n",
            "i liked this movie because i gave it a chance at the time . But i just wanted to see it again and it was just going to be a very bad movie ! It is just a huge bore . i think\n",
            "\n",
            "i liked this movie because it simply was not the best movie i have seen . Well , it was a great movie , so i just got ta see it . i was surprised with the movie .. i thought it was good\n",
            "\n",
            "i liked this movie because the movie was not only a funny movie , so i watched it . It is a great movie . It was about an English boy who lost his love . His father loved Emma\n",
            "\n",
            "i liked this movie because the Queen Elizabeth was played by Mary Van Dyke . It was also Elizabeth Taylor who played the daughter of a Englishman . The relationship between Kiera Knightley\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5C0ljk9n4C6M"
      },
      "source": [
        "As you can see, we add some randomness (we pick a random word based on the probabilities returned by the model) so we don't get exactly the same review twice. Our model doesn't have any programmed knowledge of the structure of a sentence or grammar rules, yet it has clearly learned a lot about English sentences: we can see it capitalizes properly (*I* is just transformed to *i* because our rules require two characters or more to consider a word as capitalized, so it's normal to see it lowercased) and is using consistent tense. The general review makes sense at first glance, and it's only if you read carefully that you can notice something is a bit off. Not bad for a model trained in a couple of hours! \n",
        "\n",
        "But our end goal wasn't to train a model to generate reviews, but to classify them... so let's use this model to do just that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zYo_TVf4C6M"
      },
      "source": [
        "# <center> END\n",
        "<center> We have fintuned the Language Model with the IMDb dataset.\n",
        "<center> The next step is using that model to train a classifier."
      ]
    }
  ]
}