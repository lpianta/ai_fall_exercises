{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "color-illinois",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "several-cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "controlling-camel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for EAR\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    # euclidean distances between the two sets of vertical eye landmarks (x, y)-coordinates\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "    # euclidean distance between the horizontal eye landmark (x, y)-coordinates\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "    # eye aspect ratio\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "greenhouse-there",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for MAR\n",
    "\n",
    "def mouth_aspect_ratio(mouth):\n",
    "    # euclidean distances between the two sets of vertical mouth landmarks (x, y)-coordinates\n",
    "    A = dist.euclidean(mouth[2], mouth[10])\n",
    "    B = dist.euclidean(mouth[4], mouth[8])\n",
    "    # euclidean distance between the horizontal mouth landmark (x, y)-coordinates\n",
    "    C = dist.euclidean(mouth[0], mouth[6])\n",
    "    # mouth aspect ratio\n",
    "    mar = (A + B) / (2.0 * C)\n",
    "    return mar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "muslim-bosnia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for brightness check\n",
    "\n",
    "def brightness_check(frame):\n",
    "    frame_hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = cv2.split(frame_hsv)\n",
    "    return v.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "given-chapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize detector and predictor\n",
    "faces_bboxes = dlib.cnn_face_detection_model_v1(\"../models/mmod_human_face_detector.dat\")\n",
    "landmark_predictor = dlib.shape_predictor(\"../models/dlib_shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# initialize counters and threshold\n",
    "frame_counter = 0\n",
    "ear_frame_counter = 0\n",
    "ear_threshold = []\n",
    "# hc_ear_threshold = 0.25\n",
    "\n",
    "# open videocapture from the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # update frame counter\n",
    "    frame_counter += 1\n",
    "    \n",
    "    # brightness check and adjustment\n",
    "    bright_mean = brightness_check(frame)\n",
    "    if bright_mean < 50:\n",
    "        bright_frame = cv2.addWeighted(frame, 4.3, np.zeros(frame.shape, frame.dtype), 0, 0)\n",
    "        gray = cv2.cvtColor(bright_frame, cv2.COLOR_BGR2GRAY)\n",
    "    elif 50 < bright_mean < 60:\n",
    "        bright_frame = cv2.addWeighted(frame, 2.5, np.zeros(frame.shape, frame.dtype), 0, 0)\n",
    "        gray = cv2.cvtColor(bright_frame, cv2.COLOR_BGR2GRAY)\n",
    "    elif 60 < bright_mean < 100:\n",
    "        bright_frame = cv2.addWeighted(frame, 1.6, np.zeros(frame.shape, frame.dtype), 0, 0)\n",
    "        gray = cv2.cvtColor(bright_frame, cv2.COLOR_BGR2GRAY)\n",
    "    # convert frame to grayscale\n",
    "    else:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # find faces\n",
    "    faces = faces_bboxes(gray, 0)\n",
    "    face_rect = faces.pop().rect\n",
    "\n",
    "    # initialize empty array with shape (68, 2) (the predictor return 68 facemarks x y coordinates)\n",
    "    coords = np.zeros((68, 2), dtype=\"int\") # need to specify the datatype for convexHull to work\n",
    "\n",
    "    # find landmark in bounding box\n",
    "    landmarks = landmark_predictor(gray, face_rect)\n",
    "    # loop over landmarks to update the coordinates array\n",
    "    for i in range(0, landmarks.num_parts):\n",
    "        coords[i] = (landmarks.part(i).x, landmarks.part(i).y)\n",
    "\n",
    "    # slice coords to find landmarks of eyes and mouth\n",
    "    left_eye = coords[42:48]\n",
    "    right_eye = coords[36:42]\n",
    "    mouth = coords[48:68]\n",
    "    \n",
    "    # find left and right EAR\n",
    "    left_ear = eye_aspect_ratio(left_eye)\n",
    "    right_ear = eye_aspect_ratio(right_eye)\n",
    "    \n",
    "    # average of both EARs\n",
    "    ear = (left_ear + right_ear) / 2\n",
    "\n",
    "    # find MAR\n",
    "    mar = mouth_aspect_ratio(mouth)\n",
    "\n",
    "    # find convex hull\n",
    "    leye_hull = cv2.convexHull(left_eye)\n",
    "    reye_hull = cv2.convexHull(right_eye)\n",
    "    mouth_hull = cv2.convexHull(mouth)\n",
    "    \n",
    "    # draw eye and mouth contours\n",
    "    cv2.drawContours(frame, [leye_hull], -1, (0, 255, 0), 2)\n",
    "    cv2.drawContours(frame, [reye_hull], -1, (0, 255, 0), 2)\n",
    "    cv2.drawContours(frame, [mouth_hull], -1, (0, 255, 0), 2)\n",
    "    \n",
    "    # take some time to initialize values\n",
    "    if frame_counter < 30:\n",
    "        cv2.putText(frame, \"CALIBRATING\", (20, 20), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 255))\n",
    "        ear_threshold.append(ear)\n",
    "        #print(frame_counter)\n",
    "    else:\n",
    "        # convert ear_threshold to numpy array\n",
    "        ear_threshold = np.array(ear_threshold)\n",
    "       # remove NaN values from the array\n",
    "        ear_threshold = ear_threshold[~np.isnan(ear_threshold)] # ~ = is not\n",
    "        # get the mean\n",
    "        ear_threshold = np.mean(np.array(ear_threshold))\n",
    "    \n",
    "        # print EAR and MAR\n",
    "        cv2.putText(frame, f\"EAR: {round(ear, 2)}\", (20, 20), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 255))\n",
    "        cv2.putText(frame, f\"MAR: {round(mar, 2)}\", (20, 50), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 255))\n",
    "        # check if EAR goes below the threshold for a number of frames\n",
    "        if ear < ear_threshold:\n",
    "            ear_frame_counter += 1\n",
    "            print(ear_frame_counter)\n",
    "\n",
    "            if ear_frame_counter >= 10:\n",
    "                print(\"EAR \" + str(ear))\n",
    "                print(\"THRESH \" + str(ear_threshold))\n",
    "                print(\"drowsy\")\n",
    "                cv2.putText(frame, \"WARNING!\", (20, 100), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 255))\n",
    "\n",
    "        else:\n",
    "            ear_frame_counter = 0\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    cv2.imshow('Webcam Feed', frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
